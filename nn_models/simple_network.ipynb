{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network to minimize CRPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EMOS analog is a simple network like this:\n",
    "\n",
    "![title](EMOS_network.png)\n",
    "\n",
    "In this notebook we will build this simple network in theano and use the CRPS as a cost function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mtrand.RandomState at 0x10d7c2750>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's import the libraries we need\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "# Let's make this notebook reproducible by defining the random seed\n",
    "np.random.RandomState(42)   # I don't even like the hitchhiker..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I followed this tutorial to figure out the theano basics: http://www.marekrei.com/blog/theano-tutorial/\n",
    "\n",
    "We will now attempt to build a simplle class for our model following: https://github.com/marekrei/theano-tutorial/blob/master/classifier.py\n",
    "\n",
    "So the first step is to create a class and initialize the network architecture. theano allocates a graph. This means that we first plot out the computations which will be done in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EMOS_Network(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This function is called once an object of this class is created.\n",
    "        \"\"\"\n",
    "        # Before we start with the network, let's define\n",
    "        # the learning rate as an input so we can vary it\n",
    "        lr = T.fscalar('lr')\n",
    "        \n",
    "        # First let's define the input to the network\n",
    "        # This is the ensemble mean (meanx), \n",
    "        # the ensemble stadnard deviation (stdx) and\n",
    "        # the corresponding observation (target)\n",
    "        # In theano we use tensors to describe these variables.\n",
    "        # T.fvector allocates a float32 1D vector\n",
    "        meanx = T.fvector('meanx')   # The name helps with debugging\n",
    "        stdx = T.fvector('stdx')\n",
    "        target = T.fvector('target')\n",
    "        \n",
    "        # Next we allocate the weights (a, b, c, d) as shared\n",
    "        # variables and initialize some value for them.\n",
    "        # For now we will just draw a random variable from N(0, 1)\n",
    "        a = theano.shared(np.random.randn(), 'a')\n",
    "        b = theano.shared(np.random.randn(), 'b')\n",
    "        c = theano.shared(np.random.randn(), 'c')\n",
    "        d = theano.shared(np.random.randn(), 'd')\n",
    "        \n",
    "        # Now that we have the input and the weights, \n",
    "        # we can set up the network.\n",
    "        mu = a + meanx * b\n",
    "        sigma = c + stdx * d\n",
    "        \n",
    "        # Now comes the cost function.\n",
    "        # To stop sigma from becoming negative we first have to \n",
    "        # convert it the the variance and then take the square\n",
    "        # root again. (I learned from experience...)\n",
    "        # This part of the code is inspired by Kai Polsterer's code!\n",
    "        var = T.sqr(sigma)\n",
    "        # The following three variables are just for convenience\n",
    "        loc = (target - mu) / T.sqrt(var)\n",
    "        phi = 1.0 / np.sqrt(2.0 * np.pi) * T.exp(-T.square(loc) / 2.0)\n",
    "        Phi = 0.5 * (1.0 + T.erf(loc / np.sqrt(2.0)))\n",
    "        # First we will compute the crps for each input/target pair\n",
    "        crps =  T.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
    "        # Then we take the mean. The cost is now a scalar\n",
    "        mean_crps = T.mean(crps)\n",
    "        \n",
    "        # Now compute the gradients of the cost function \n",
    "        # with respect to the four weights/parameters\n",
    "        params = [a, b, c, d]   # Let's put them in a list for convenience\n",
    "        gradients = theano.tensor.grad(mean_crps, params)\n",
    "        \n",
    "        # For gradient descent we now need to subtract the gradients\n",
    "        # from our parameters to minimize the cost function\n",
    "        # In theano we want to define a list of tuples containing\n",
    "        # the old parameter and the updated parameter.\n",
    "        updates = [(p, p - lr * g) for p, g in zip(params, gradients)]\n",
    "        \n",
    "        # So far no actual computations have been done. Now we will\n",
    "        # define a Theano function, which takes input, does some \n",
    "        # calculations and returns some output. In our case, we use \n",
    "        # meanx, stdx and the target as an input plus the required \n",
    "        # learning rate and return the mean_crps\n",
    "        # as an output. Then we tell the function to apply the update\n",
    "        # every time it is called. This is the training\n",
    "        self.train = theano.function([meanx, stdx, target, lr], \n",
    "                                     mean_crps, updates=updates)\n",
    "        # Furthermore, we define a method for simply making a prediction\n",
    "        # and returning the predicted values of mu and sigma\n",
    "        # along with the mean_crps without updating the parameters\n",
    "        self.predict = theano.function([meanx, stdx, target],\n",
    "                                       [mu, sigma, mean_crps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's define some input arrays\n",
    "nb_data = 100  # Number of data\n",
    "# It is important that the input has the same type (float32) as the Theano tensors\n",
    "in_meanx = np.asarray(np.random.randn(nb_data) + 3, dtype='float32')   # Random with mean 3 and std 1\n",
    "in_stdx = np.asarray(2 * np.random.randn(nb_data) + 1, dtype='float32')\n",
    "in_target = np.asarray(1.5 * np.random.randn(nb_data) + 2, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a perfect training set, where we should get perfect results\n",
    "in_meanx = np.ones(nb_data, dtype='float32') * 3\n",
    "in_stdx = np.ones(nb_data, dtype='float32') * 3\n",
    "in_target = np.ones(nb_data, dtype='float32') * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have set up our model and created some simple test data. Let's now initialize the network and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "model = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0; mean_crps = 2.790\n",
      "Step 10; mean_crps = 2.722\n",
      "Step 20; mean_crps = 2.656\n",
      "Step 30; mean_crps = 2.592\n",
      "Step 40; mean_crps = 2.531\n",
      "Step 50; mean_crps = 2.472\n",
      "Step 60; mean_crps = 2.415\n",
      "Step 70; mean_crps = 2.359\n",
      "Step 80; mean_crps = 2.306\n",
      "Step 90; mean_crps = 2.254\n",
      "Step 100; mean_crps = 2.204\n",
      "Step 110; mean_crps = 2.156\n",
      "Step 120; mean_crps = 2.109\n",
      "Step 130; mean_crps = 2.064\n",
      "Step 140; mean_crps = 2.020\n",
      "Step 150; mean_crps = 1.978\n",
      "Step 160; mean_crps = 1.937\n",
      "Step 170; mean_crps = 1.897\n",
      "Step 180; mean_crps = 1.859\n",
      "Step 190; mean_crps = 1.822\n",
      "Step 200; mean_crps = 1.786\n",
      "Step 210; mean_crps = 1.751\n",
      "Step 220; mean_crps = 1.717\n",
      "Step 230; mean_crps = 1.684\n",
      "Step 240; mean_crps = 1.653\n",
      "Step 250; mean_crps = 1.622\n",
      "Step 260; mean_crps = 1.592\n",
      "Step 270; mean_crps = 1.563\n",
      "Step 280; mean_crps = 1.534\n",
      "Step 290; mean_crps = 1.507\n",
      "Step 300; mean_crps = 1.480\n",
      "Step 310; mean_crps = 1.455\n",
      "Step 320; mean_crps = 1.429\n",
      "Step 330; mean_crps = 1.405\n",
      "Step 340; mean_crps = 1.381\n",
      "Step 350; mean_crps = 1.358\n",
      "Step 360; mean_crps = 1.336\n",
      "Step 370; mean_crps = 1.314\n",
      "Step 380; mean_crps = 1.293\n",
      "Step 390; mean_crps = 1.272\n",
      "Step 400; mean_crps = 1.252\n",
      "Step 410; mean_crps = 1.232\n",
      "Step 420; mean_crps = 1.213\n",
      "Step 430; mean_crps = 1.194\n",
      "Step 440; mean_crps = 1.176\n",
      "Step 450; mean_crps = 1.158\n",
      "Step 460; mean_crps = 1.141\n",
      "Step 470; mean_crps = 1.124\n",
      "Step 480; mean_crps = 1.108\n",
      "Step 490; mean_crps = 1.092\n"
     ]
    }
   ],
   "source": [
    "# Let's run over the data a few times and print out the crps every few steps\n",
    "# Note that this is simply gradient descent, not stochastic, since\n",
    "# we are giving the algorithm all the data for each update/\n",
    "lr = np.asarray(0.001, dtype='float32')\n",
    "for i in range(500):\n",
    "    cost = model.train(in_meanx, in_stdx, in_target, lr)\n",
    "    if i%10 == 0: print('Step %i; mean_crps = %.3f' % (i, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(in_meanx, in_stdx, in_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41526058,  0.41526058,  0.41526058,  0.41526058,  0.41526058])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good so far, we are able to reduce the CRPS and also get the correct predictions where possible. So now we can actually start thinking about real data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's load some real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy this from the python_data_handling notebook. \n",
    "# Eventually this function will go in a separate file\n",
    "from netCDF4 import Dataset\n",
    "# Define directory where interpolated files are stored.\n",
    "# DATA_DIR = '/project/meteo/w2w/C7/ppnn_data/'   # At LMU\n",
    "DATA_DIR = '/Users/stephanrasp/repositories/ppnn/data/'  # Mac\n",
    "# Define file name\n",
    "fn = 'data_interpolated.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rg = Dataset(DATA_DIR + 'data_interpolated.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from netCDF4 import num2date\n",
    "def get_data_slice(rg, month, utc=0):\n",
    "    # Get array of datetime objects\n",
    "    dates = num2date(rg.variables['time'][:],\n",
    "                     units='seconds since 1970-01-01 00:00 UTC')\n",
    "    # Extract months and hours\n",
    "    months = np.array([d.month for d in list(dates)])\n",
    "    hours = np.array([d.hour for d in list(dates)])\n",
    "    \n",
    "    # for now I need to include the Kelvin fix\n",
    "    tfc = rg.variables['t2m_fc'][:]\n",
    "    idx = np.where(np.mean(tfc, axis=(1, 2)) > 100)[0][0]\n",
    "    tfc[idx:] = tfc[idx:] - 273.15\n",
    "    \n",
    "    # Extract the requested data\n",
    "    tobs = rg.variables['t2m_obs'][(months == 1) & (hours == 0)]\n",
    "    tfc = tfc[(months == 1) & (hours == 0)]\n",
    "    return tobs, tfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's load the data for all of Jan for 00UTC init\n",
    "tobs, tfc = get_data_slice(rg, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have to compute the mean and std for the ensemble\n",
    "tfc_mean = np.mean(tfc, axis=1, dtype='float32')\n",
    "tfc_std = np.std(tfc, axis=1, ddof=1, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 537)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfc_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 537)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten to 1D\n",
    "tobs = np.ravel(np.asarray(tobs, dtype='float32'))\n",
    "tfc_mean = np.ravel(tfc_mean)\n",
    "tfc_std = np.ravel(tfc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166470,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14361"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(tobs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out nans\n",
    "mask = np.isfinite(tobs)\n",
    "tobs = tobs[mask]\n",
    "tfc_mean = tfc_mean[mask]\n",
    "tfc_std = tfc_std[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the 1D arrays we need. Time to feed them to the learning network and learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "model = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's first check what our CRPS is without training\n",
    "from scipy.stats import norm\n",
    "def crps_normal(mu, sigma, y):\n",
    "    loc = (y - mu) / sigma\n",
    "    crps = sigma * (loc * (2 * norm.cdf(loc) - 1) + \n",
    "                    2 * norm.pdf(loc) - 1. / np.sqrt(np.pi))\n",
    "    return crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.35477760093263"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crps_normal(tfc_mean, tfc_std, tobs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's try training.\n",
    "1. Gradient descent with all data and a learning rate of 0.1. Still learning after 500 steps. So after around 2000 steps we get a CRPS of around 1.113 which is lower than the EMOS global for Jan, but of course this is not a fair comparison.\n",
    "2. Can we use a much higher learning rate with standard gradient descent? Try 0.5. Doesn't seem like it is working very well. Yes, 0.1 is much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Were still masked arrays\n",
    "tfc_mean = np.asarray(tfc_mean, dtype='float32')\n",
    "tfc_std = np.asarray(tfc_std, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0; mean_crps = 2.967\n",
      "Step 100; mean_crps = 1.117\n",
      "Step 200; mean_crps = 1.115\n",
      "Step 300; mean_crps = 1.115\n",
      "Step 400; mean_crps = 1.114\n",
      "Step 500; mean_crps = 1.114\n",
      "Step 600; mean_crps = 1.114\n",
      "Step 700; mean_crps = 1.114\n",
      "Step 800; mean_crps = 1.114\n",
      "Step 900; mean_crps = 1.114\n"
     ]
    }
   ],
   "source": [
    "# Let's train. Try gradient descent with all data at once\n",
    "lr = np.asarray(0.1, dtype='float32')\n",
    "for i in range(1000):\n",
    "    cost = model.train(tfc_mean, tfc_std, tobs, lr)\n",
    "    if i%100 == 0: print('Step %i; mean_crps = %.3f' % (i, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 t2m_obs(time, station)\n",
       "    units: deg_C\n",
       "    _FillValue: nan\n",
       "    long_name: t2m station observation\n",
       "unlimited dimensions: \n",
       "current shape = (7306, 537)\n",
       "filling on"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the next step would be to update the data handling function to return the \n",
    "# data from the last 25 days\n",
    "rg.variables['t2m_obs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rolling_slice(rg, date_idx, window_size=25, utc=0):\n",
    "    \"\"\"\n",
    "    Return the forecast and observation data from the \n",
    "    previous *window_size* days. So if date_idx=10 and \n",
    "    window_size=3, it would get the data for indices 7, 8, 9.\n",
    "    \"\"\"\n",
    "    # Get array of datetime objects\n",
    "    dates = num2date(rg.variables['time'][:],\n",
    "                     units='seconds since 1970-01-01 00:00 UTC')\n",
    "    # Extract months and hours\n",
    "    months = np.array([d.month for d in list(dates)])\n",
    "    hours = np.array([d.hour for d in list(dates)])\n",
    "    \n",
    "    # for now I need to include the Kelvin fix\n",
    "    tfc = rg.variables['t2m_fc'][:]\n",
    "    idx = np.where(np.mean(tfc, axis=(1, 2)) > 100)[0][0]\n",
    "    tfc[idx:] = tfc[idx:] - 273.15\n",
    "    \n",
    "    # Extract the requested data\n",
    "    tobs = rg.variables['t2m_obs'][(hours == utc)]\n",
    "    tfc = tfc[(hours == utc)]\n",
    "    \n",
    "    # Get the correct indices\n",
    "    idx_start = date_idx - window_size\n",
    "    idx_stop = date_idx\n",
    "    \n",
    "    # Get the slice for the indices\n",
    "    tobs = tobs[idx_start:idx_stop]\n",
    "    tfc = tfc[idx_start:idx_stop]\n",
    "    \n",
    "    return tobs, tfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobs_roll, tfc_roll = get_rolling_slice(rg, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 50, 537)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfc_roll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function compute means and std and flatten\n",
    "def prep_data(tobs, tfc):\n",
    "    ax = 0 if tobs.ndim == 1 else 1\n",
    "    # Compute mean and std and convert to float32\n",
    "    tfc_mean = np.mean(np.asarray(tfc, dtype='float32'), axis=ax)\n",
    "    tfc_std = np.std(np.asarray(tfc, dtype='float32'), axis=ax, ddof=1)\n",
    "    tobs = np.asarray(tobs, dtype='float32')\n",
    "    \n",
    "    # Flatten\n",
    "    tobs = np.ravel(tobs)\n",
    "    tfc_mean = np.ravel(tfc_mean)\n",
    "    tfc_std = np.ravel(tfc_std)\n",
    "    \n",
    "    # Remove NaNs\n",
    "    mask = np.isfinite(tobs)\n",
    "    tobs = tobs[mask]\n",
    "    tfc_mean = tfc_mean[mask]\n",
    "    tfc_std = tfc_std[mask]\n",
    "    \n",
    "    return tobs, tfc_mean, tfc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobs_roll, tfc_mean_roll, tfc_std_roll = prep_data(tobs_roll, tfc_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11308,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfc_mean_roll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's train again.\n",
    "model = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0; mean_crps = 1.047\n",
      "Step 10; mean_crps = 1.046\n",
      "Step 20; mean_crps = 1.045\n",
      "Step 30; mean_crps = 1.044\n",
      "Step 40; mean_crps = 1.044\n",
      "Step 50; mean_crps = 1.044\n",
      "Step 60; mean_crps = 1.043\n",
      "Step 70; mean_crps = 1.043\n",
      "Step 80; mean_crps = 1.043\n",
      "Step 90; mean_crps = 1.043\n"
     ]
    }
   ],
   "source": [
    "lr = np.asarray(0.1, dtype='float32')\n",
    "for i in range(100):\n",
    "    cost = model.train(tfc_mean_roll, tfc_std_roll, tobs_roll, lr)\n",
    "    if i%10 == 0: print('Step %i; mean_crps = %.3f' % (i, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems to take max 200 steps to find the minimum. Time to actually loop over all the dates and compute the actual score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's actually modify the slicing function and feed it the full data.\n",
    "# Because something took quite long earlier...\n",
    "tobs_full = rg.variables['t2m_obs'][:]\n",
    "tfc_full = rg.variables['t2m_fc'][:]\n",
    "dates = num2date(rg.variables['time'][:],\n",
    "                     units='seconds since 1970-01-01 00:00 UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = np.array([d.month for d in list(dates)])\n",
    "hours = np.array([d.hour for d in list(dates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.where(np.mean(tfc_full, axis=(1, 2)) > 100)[0][0]\n",
    "tfc_full[idx:] = tfc_full[idx:] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can also alread get all the 00UTC data\n",
    "tfc_full = tfc_full[hours == 0]\n",
    "tobs_full = tobs_full[hours == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rolling_slice(tobs_full, tfc_full, date_idx, window_size=25, \n",
    "                      fclt=48):\n",
    "    \"\"\"\n",
    "    Return the forecast and observation data from the \n",
    "    previous *window_size* days. So if date_idx=10 and \n",
    "    window_size=3, it would get the data for indices 7, 8, 9.\n",
    "    Nope, also have to go back the forecast lead time.\n",
    "    \"\"\"\n",
    "    fclt_didx = int(fclt / 24)\n",
    "    \n",
    "    # Get the correct indices\n",
    "    idx_start = date_idx - window_size - fclt_didx\n",
    "    idx_stop = date_idx - fclt_didx\n",
    "    \n",
    "    # Get the slice for the indices\n",
    "    tobs_roll = tobs_full[idx_start:idx_stop]\n",
    "    tfc_roll = tfc_full[idx_start:idx_stop]\n",
    "    \n",
    "    return tobs_roll, tfc_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_00 = dates[hours == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3653,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_00.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do it fully for the first time step with predicting the current date\n",
    "date_idx = 100\n",
    "window_size = 50\n",
    "tobs_roll, tfc_roll = get_rolling_slice(tobs_full, tfc_full, date_idx, \n",
    "                                        window_size)\n",
    "tobs_date, tfc_date = (tobs_full[date_idx], tfc_full[date_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobs_date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tobs_roll, tfc_mean_roll, tfc_std_roll = prep_data(tobs_roll, tfc_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobs_date, tfc_mean_date, tfc_std_date = prep_data(tobs_date, tfc_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.69999981,  2.5999999 ,  3.0999999 , ...,  8.30000019,\n",
       "        9.80000019,  6.30000019], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobs_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0; mean_crps = 4.321\n",
      "Step 10; mean_crps = 1.171\n",
      "Step 20; mean_crps = 1.146\n",
      "Step 30; mean_crps = 1.126\n",
      "Step 40; mean_crps = 1.111\n",
      "Step 50; mean_crps = 1.100\n",
      "Step 60; mean_crps = 1.092\n",
      "Step 70; mean_crps = 1.087\n",
      "Step 80; mean_crps = 1.083\n",
      "Step 90; mean_crps = 1.081\n",
      "Step 100; mean_crps = 1.080\n",
      "Step 110; mean_crps = 1.079\n",
      "Step 120; mean_crps = 1.078\n",
      "Step 130; mean_crps = 1.078\n",
      "Step 140; mean_crps = 1.077\n",
      "Step 150; mean_crps = 1.077\n",
      "Step 160; mean_crps = 1.077\n",
      "Step 170; mean_crps = 1.077\n",
      "Step 180; mean_crps = 1.077\n",
      "Step 190; mean_crps = 1.077\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    cost = model.train(tfc_mean_roll, tfc_std_roll, tobs_roll, lr)\n",
    "    if i%10 == 0: print('Step %i; mean_crps = %.3f' % (i, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.253791908507415)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now make a prediction for the actual day\n",
    "model.predict(tfc_mean_date, tfc_std_date, tobs_date)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2007, 1, 28, 0, 0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_00[date_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([363]),)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "np.where(dates_00 == datetime.datetime(2008, 1, 1, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3650]),)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dates_00 == datetime.datetime(2016, 12, 31, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-02-07 00:00:00\n",
      "2008-03-28 00:00:00\n",
      "2008-05-17 00:00:00\n",
      "2008-07-06 00:00:00\n",
      "2008-08-25 00:00:00\n",
      "2008-10-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Now let's actually loop\n",
    "crps_train_list = []\n",
    "crps_predict_list = []\n",
    "lr = np.asarray(0.1, dtype='float32')\n",
    "window_size = 50\n",
    "for date_idx in range(363, 3651):   # Just try 50 days\n",
    "    if date_idx % 50 == 0:\n",
    "        print(dates_00[date_idx])\n",
    "    tobs_roll, tfc_roll = get_rolling_slice(tobs_full, tfc_full, date_idx, \n",
    "                                            window_size)\n",
    "    tobs_date, tfc_date = (tobs_full[date_idx], tfc_full[date_idx])\n",
    "    tobs_roll, tfc_mean_roll, tfc_std_roll = prep_data(tobs_roll, tfc_roll)\n",
    "    tobs_date, tfc_mean_date, tfc_std_date = prep_data(tobs_date, tfc_date)\n",
    "    \n",
    "    model = EMOS_Network()\n",
    "    for i in range(200):\n",
    "        cost = model.train(tfc_mean_roll, tfc_std_roll, tobs_roll, lr)\n",
    "    crps_train_list.append(cost)\n",
    "    \n",
    "    crps_pred = model.predict(tfc_mean_date, tfc_std_date, tobs_date)[2]\n",
    "    crps_predict_list.append(crps_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the data. Its past midingt and I can't be bothered to save them anywhere useful...\n",
    "np.save('./EMOS_network_crps_train.npy', crps_train_list)\n",
    "np.save('./EMOS_network_crps_predict.npy', crps_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(crps_train_list)\n",
    "plt.plot(crps_predict_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
