{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network to minimize CRPS\n",
    "\n",
    "**Steps (to be updated)**\n",
    "1. Set up network structure (first here, then probably in separate module)\n",
    "2. Try feeding some data to the model and sanity-check the output\n",
    "3. Run the network on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EMOS analog is a simple network like this:\n",
    "\n",
    "![title](EMOS_network.png)\n",
    "\n",
    "I will try to build a basic model like this in Keras, since this is the simplest library. There are two complications: \n",
    "\n",
    "1. This is not a fully connected layer, so we have to find a workaround, but I think something like this should work: https://github.com/fchollet/keras/issues/3919\n",
    "2. We need to write a custom CRPS loss function. We should probably use theano as a backend to make it compatible with Kai P.'s code. Example for keras loss functions: https://keras.io/losses/ or here: https://github.com/fchollet/keras/issues/369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why do we have to write that function extra. They are hooks for interacting with the graph... aha.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok here we go... http://www.marekrei.com/blog/theano-tutorial/\n",
    "\n",
    "# Let's create variables for the input\n",
    "meanx = theano.tensor.fscalar('meanx')   # This is for 32 bit floats\n",
    "\n",
    "# Now the weights and biases a and b\n",
    "a = theano.shared(np.asarray(0.5), 'a')  # The explisit names help with debugging\n",
    "b = theano.shared(np.asarray(2.), 'b')  # Make sure this is a float!!!\n",
    "\n",
    "# Let's define mu, this set's up the graph\n",
    "mu = meanx * b + a\n",
    "\n",
    "# And a function that takes input and returns output\n",
    "# What happens without the brackets? Error: Input variables of a Theano function should be contained in a list, even when there is a single input.\n",
    "f = theano.function([meanx], mu)\n",
    "\n",
    "# Let's evaluate the output\n",
    "# Can I leave out the brackets here?\n",
    "# Nope: Wrong number of dimensions: expected 1, got 0 with shape ().\n",
    "out = f(1)\n",
    "\n",
    "# So the input to f can either be a 1D numpy array with float32 or a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5,  4.5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let' now actaully train.\n",
    "\n",
    "# Does my graph still exist?\n",
    "f(np.asarray([1, 2], dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes. \n",
    "\n",
    "# Define a target\n",
    "target = theano.tensor.fscalar('target')\n",
    "\n",
    "# Define a loss/cost function, simple squared distance\n",
    "cost = theano.tensor.sqr(target - mu)\n",
    "# This needs to be a scalar, so we need to define the input x as a scalar\n",
    "# For now, I guess later we can define both x and target as vectors.\n",
    "\n",
    "# Compute partial derivatives of cost function with respect to weights\n",
    "gradients = theano.tensor.grad(cost, [a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create updated variables\n",
    "a_updated = a - (0.01 * gradients[0])\n",
    "b_updated = b - (0.01 * gradients[1])\n",
    "\n",
    "# And write a function that replaces the pld variable with the updated value\n",
    "updates = [(a, a_updated), (b, b_updated)]\n",
    "\n",
    "# Now lets define a function again to do something\n",
    "f = theano.function([meanx, target], mu, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5527.95796295493\n",
      "5.587731639540578\n",
      "2.0023293369952597\n",
      "2.000001512323491\n",
      "2.000000000981877\n",
      "2.0000000000006377\n",
      "2.0000000000000004\n",
      "2.0\n",
      "2.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "# Now let's train\n",
    "for i in range(100):\n",
    "    out = f(5, 2)   # Start with input 5 and target 2\n",
    "    if i%10 == 0: print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works, somewhat, but I feel like this is very clumsy and I don't actually want to write the code this way. But before looking at better code, I should maybe try to include the variance and CRPS cost function.\n",
    "\n",
    "But wait, why was the initial guess so freaking far off... Something might be wrong here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the mean part from above and add the std\n",
    "\n",
    "# Let's create variables for the input\n",
    "meanx = theano.tensor.fscalar('meanx')   # This is for 32 bit floats\n",
    "stdx = theano.tensor.fscalar('stdx')\n",
    "\n",
    "# Now the weights and biases a and b\n",
    "a = theano.shared(np.asarray(0.5), 'a')  # The explisit names help with debugging\n",
    "b = theano.shared(np.asarray(2.), 'b')  # Make sure this is a float!!!\n",
    "c = theano.shared(np.asarray(0.5), 'c')\n",
    "d = theano.shared(np.asarray(2.), 'd') \n",
    "\n",
    "# Let's define mu and also sigma\n",
    "mu = meanx * b + a\n",
    "sigma = stdx * d + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "# Now the target which is still a scalar\n",
    "target = theano.tensor.fscalar('target')\n",
    "\n",
    "# And here comes the cost function\n",
    "# First a little helper variable to keep the equation short\n",
    "\n",
    "# Will this simple fix be enough to avoid the negative std problem\n",
    "var = T.sqr(sigma)\n",
    "\n",
    "loc = (target - mu) / T.sqrt(var)\n",
    "\n",
    "# This is now copied from Kai P.'s code\n",
    "phi = 1.0 / np.sqrt(2.0 * np.pi) * T.exp(-T.square(loc) / 2.0)\n",
    "Phi = 0.5 * (1.0 + T.erf(loc / np.sqrt(2.0)))\n",
    "\n",
    "crps =  T.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
    "\n",
    "# Now compute the gradients\n",
    "gradients = theano.tensor.grad(crps, [a, b, c, d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's not define the updates\n",
    "lr = 0.01   # Learning rate\n",
    "\n",
    "a_updated = a - (lr * gradients[0])\n",
    "b_updated = b - (lr * gradients[1])\n",
    "c_updated = c - (lr * gradients[2])\n",
    "d_updated = d - (lr * gradients[3])\n",
    "\n",
    "updates = [(a, a_updated), (b, b_updated), (c, c_updated), (d, d_updated)]\n",
    "\n",
    "# Ok, so what does the function do:\n",
    "# The first argument, the list defines the input, \n",
    "# the second argument defines the output, can that be more than one?\n",
    "f = theano.function([meanx, stdx, target], [mu, sigma, crps], \n",
    "                    updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(6.5), array(10.5), array(3.2116223906950925)]\n",
      "[array(6.172896841328296), array(10.069281985719517), array(3.0333349789339605)]\n",
      "[array(5.856064480234552), array(9.627477198409583), array(2.8579359052154905)]\n",
      "[array(5.549384423566165), array(9.175080822190472), array(2.6852198566143)]\n",
      "[array(5.252767827338031), array(8.712543922329491), array(2.51500267424618)]\n",
      "[array(4.966156339250551), array(8.240277144289273), array(2.347118863001946)]\n",
      "[array(4.689523638032825), array(7.758653774689849), array(2.1814194874355133)]\n",
      "[array(4.422877827258022), array(7.268012205597393), array(2.0177703969119394)]\n",
      "[array(4.166264920204845), array(6.768657816241148), array(1.8560507365893308)]\n",
      "[array(3.919773772063541), array(6.260864253742679), array(1.6961517129811856)]\n"
     ]
    }
   ],
   "source": [
    "# Now let's do some training\n",
    "for i in range(100):\n",
    "    out = f(3, 5, 2)   # Start with input: [meanx = 3, stdx = 5, target = 2]\n",
    "    if i%10 == 0: print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(3.6835430045169386), array(5.744874051278793), array(1.5379755949408345)]\n",
      "[array(2.0110420472174706), array(0.1576020372779714), array(0.037139314934789745)]\n",
      "[array(1.9921016365325739), array(0.0549723980200141), array(0.013298726433425246)]\n",
      "[array(2.0054474051467346), array(-0.013570682845248927), array(0.004032216969526256)]\n",
      "[array(2.0180540055771665), array(-0.10893616183902224), array(0.026648781552628186)]\n",
      "[array(2.0964848350399143), array(0.147454903282231), array(0.0587844456704483)]\n",
      "[array(1.986253381720927), array(-0.0015220247658093433), array(0.012887907760301742)]\n",
      "[array(1.9559260455422292), array(0.12170837275047497), array(0.03474123110034233)]\n",
      "[array(2.0058490039752845), array(-0.046442732848182636), array(0.011146916184997418)]\n",
      "[array(2.0493908057584203), array(-0.1084959531987393), array(0.03417312722588535)]\n"
     ]
    }
   ],
   "source": [
    "# Yes, let's do some more training\n",
    "for i in range(1000):\n",
    "    out = f(3, 5, 2)   # Start with input: [meanx = 3, stdx = 5, target = 2]\n",
    "    if i%100 == 0: print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok wow what happened here, it got to almost perfect, but then skyrocketed off somewhere... How can the crps be negative? I get negative standard deviations.... This means I have to actually put the square in there somewhere. So let's actually use the variance instead! This looks good. Thanks Kai!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for now we can only put in scalars, while in reality we would like to put in arrays. So let's modify our code to allow for several fcs and obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy again!\n",
    "# But let's use a 1D vector this time\n",
    "meanx = theano.tensor.fvector('meanx')   # This is for 32 bit floats\n",
    "stdx = theano.tensor.fvector('stdx')\n",
    "\n",
    "# Now the weights and biases a and b\n",
    "a = theano.shared(np.asarray(0.5), 'a')  # The explisit names help with debugging\n",
    "b = theano.shared(np.asarray(2.), 'b')  # Make sure this is a float!!!\n",
    "c = theano.shared(np.asarray(0.5), 'c')\n",
    "d = theano.shared(np.asarray(2.), 'd') \n",
    "\n",
    "# Let's define mu and also sigma\n",
    "mu = meanx * b + a\n",
    "sigma = stdx * d + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we also have to change the target input to a vectory\n",
    "target = theano.tensor.fvector('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The cost function still has to return a scalar, so we will take the mean \n",
    "var = T.sqr(sigma)\n",
    "loc = (target - mu) / T.sqrt(var)\n",
    "# This is now copied from Kai P.'s code\n",
    "phi = 1.0 / np.sqrt(2.0 * np.pi) * T.exp(-T.square(loc) / 2.0)\n",
    "Phi = 0.5 * (1.0 + T.erf(loc / np.sqrt(2.0)))\n",
    "\n",
    "crps =  T.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
    "CRPS = T.mean(crps)\n",
    "\n",
    "# Now compute the gradients\n",
    "gradients = theano.tensor.grad(CRPS, [a, b, c, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's not define the updates\n",
    "lr = 0.01   # Learning rate\n",
    "\n",
    "a_updated = a - (lr * gradients[0])\n",
    "b_updated = b - (lr * gradients[1])\n",
    "c_updated = c - (lr * gradients[2])\n",
    "d_updated = d - (lr * gradients[3])\n",
    "\n",
    "updates = [(a, a_updated), (b, b_updated), (c, c_updated), (d, d_updated)]\n",
    "\n",
    "# Ok, so what does the function do:\n",
    "# The first argument, the list defines the input, \n",
    "# the second argument defines the output, can that be more than one?\n",
    "\n",
    "# Let's now actually return the four weights and the mean CRPS\n",
    "f = theano.function([meanx, stdx, target], [a, b, c, d, CRPS], \n",
    "                    updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's define some input arrays\n",
    "nb_data = 100  # Number of data\n",
    "in_meanx = np.asarray(np.random.randn(nb_data) + 3, dtype='float32')   # Random with mean 3 and std 1\n",
    "in_stdx = np.asarray(2 * np.random.randn(nb_data) + 1, dtype='float32')\n",
    "in_target = np.asarray(1.5 * np.random.randn(nb_data) + 2, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = f(in_meanx, in_stdx, in_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.49334241949446894),\n",
       " array(1.9784306672279734),\n",
       " array(0.5007316959309528),\n",
       " array(2.0004942449420238),\n",
       " array(3.50234543323941)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(1.730620087048809), array(0.06644880405138838), array(1.4827481952684731), array(0.009317388676805285), array(0.8512899069094731)]\n",
      "[array(1.7344547140655597), array(0.06529631112669755), array(1.4826027379610665), array(0.009346970911675379), array(0.8512882834960577)]\n",
      "[array(1.7371037852117128), array(0.06450021021093287), array(1.4824934799112637), array(0.009369635469623851), array(0.8512875085458209)]\n",
      "[array(1.7389338709270818), array(0.06395024587064241), array(1.482416063087569), array(0.009385857957330527), array(0.851287138661258)]\n",
      "[array(1.7401981448712545), array(0.06357031670432199), array(1.482362238236333), array(0.009397205673835831), array(0.8512869621321053)]\n",
      "[array(1.7410715195142321), array(0.06330785665305479), array(1.4823250418608427), array(0.009405078694548085), array(0.8512868778885001)]\n",
      "[array(1.741674844128684), array(0.06312654932356954), array(1.4822993790674543), array(0.009410524922049938), array(0.8512868376874936)]\n",
      "[array(1.742091612442789), array(0.06300130429382261), array(1.4822816770408667), array(0.009414288487493237), array(0.8512868185042173)]\n",
      "[array(1.742379506960205), array(0.06291478751286192), array(1.4822694636178346), array(0.00941688836323096), array(0.8512868093504709)]\n",
      "[array(1.7425783766469087), array(0.06285502396274566), array(1.4822610346295217), array(0.00941868417886523), array(0.8512868049826156)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Yes, let's do some more training\n",
    "for i in range(10000):\n",
    "    out = f(in_meanx, in_stdx, in_target)   # Start with input: [meanx = 3, stdx = 5, target = 2]\n",
    "    if i%1000 == 0: print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so 0.85 seems to be the lowest CRPS to get with this input data!\n",
    "\n",
    "Ok, nice, we have extended our approach to vector input data. Now it is probably time to clean up and check out a litlle bit how to write good theano code. Then we can feed real data to the algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
