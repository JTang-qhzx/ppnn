{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network to minimize CRPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EMOS analog is a simple network like this:\n",
    "\n",
    "![title](EMOS_network.png)\n",
    "\n",
    "In this notebook we will build this simple network in theano and use the CRPS as a cost function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mtrand.RandomState at 0x10d7c2750>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's import the libraries we need\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "# Let's make this notebook reproducible by defining the random seed\n",
    "np.random.RandomState(42)   # I don't even like the hitchhiker..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I followed this tutorial to figure out the theano basics: http://www.marekrei.com/blog/theano-tutorial/\n",
    "\n",
    "We will now attempt to build a simplle class for our model following: https://github.com/marekrei/theano-tutorial/blob/master/classifier.py\n",
    "\n",
    "So the first step is to create a class and initialize the network architecture. theano allocates a graph. This means that we first plot out the computations which will be done in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EMOS_Network(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This function is called once an object of this class is created.\n",
    "        \"\"\"\n",
    "        # Before we start with the network, let's define\n",
    "        # the learning rate as an input so we can vary it\n",
    "        lr = T.fscalar('lr')\n",
    "        \n",
    "        # First let's define the input to the network\n",
    "        # This is the ensemble mean (meanx), \n",
    "        # the ensemble stadnard deviation (stdx) and\n",
    "        # the corresponding observation (target)\n",
    "        # In theano we use tensors to describe these variables.\n",
    "        # T.fvector allocates a float32 1D vector\n",
    "        meanx = T.fvector('meanx')   # The name helps with debugging\n",
    "        stdx = T.fvector('stdx')\n",
    "        target = T.fvector('target')\n",
    "        \n",
    "        # Next we allocate the weights (a, b, c, d) as shared\n",
    "        # variables and initialize some value for them.\n",
    "        # For now we will just draw a random variable from N(0, 1)\n",
    "        a = theano.shared(np.random.randn(), 'a')\n",
    "        b = theano.shared(np.random.randn(), 'b')\n",
    "        c = theano.shared(np.random.randn(), 'c')\n",
    "        d = theano.shared(np.random.randn(), 'd')\n",
    "        \n",
    "        # Now that we have the input and the weights, \n",
    "        # we can set up the network.\n",
    "        mu = a + meanx * b\n",
    "        sigma = c + stdx * d\n",
    "        \n",
    "        # Now comes the cost function.\n",
    "        # To stop sigma from becoming negative we first have to \n",
    "        # convert it the the variance and then take the square\n",
    "        # root again. (I learned from experience...)\n",
    "        # This part of the code is inspired by Kai Polsterer's code!\n",
    "        var = T.sqr(sigma)\n",
    "        # The following three variables are just for convenience\n",
    "        loc = (target - mu) / T.sqrt(var)\n",
    "        phi = 1.0 / np.sqrt(2.0 * np.pi) * T.exp(-T.square(loc) / 2.0)\n",
    "        Phi = 0.5 * (1.0 + T.erf(loc / np.sqrt(2.0)))\n",
    "        # First we will compute the crps for each input/target pair\n",
    "        crps =  T.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
    "        # Then we take the mean. The cost is now a scalar\n",
    "        mean_crps = T.mean(crps)\n",
    "        \n",
    "        # Now compute the gradients of the cost function \n",
    "        # with respect to the four weights/parameters\n",
    "        params = [a, b, c, d]   # Let's put them in a list for convenience\n",
    "        gradients = theano.tensor.grad(mean_crps, params)\n",
    "        \n",
    "        # For gradient descent we now need to subtract the gradients\n",
    "        # from our parameters to minimize the cost function\n",
    "        # In theano we want to define a list of tuples containing\n",
    "        # the old parameter and the updated parameter.\n",
    "        updates = [(p, p - lr * g) for p, g in zip(params, gradients)]\n",
    "        \n",
    "        # So far no actual computations have been done. Now we will\n",
    "        # define a Theano function, which takes input, does some \n",
    "        # calculations and returns some output. In our case, we use \n",
    "        # meanx, stdx and the target as an input plus the required \n",
    "        # learning rate and return the mean_crps\n",
    "        # as an output. Then we tell the function to apply the update\n",
    "        # every time it is called. This is the training\n",
    "        self.train = theano.function([meanx, stdx, target, lr], \n",
    "                                     mean_crps, updates=updates)\n",
    "        # Furthermore, we define a method for simply making a prediction\n",
    "        # and returning the predicted values of mu and sigma\n",
    "        # along with the mean_crps without updating the parameters\n",
    "        self.predict = theano.function([meanx, stdx, target],\n",
    "                                       [mu, sigma, mean_crps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's define some input arrays\n",
    "nb_data = 100  # Number of data\n",
    "# It is important that the input has the same type (float32) as the Theano tensors\n",
    "in_meanx = np.asarray(np.random.randn(nb_data) + 3, dtype='float32')   # Random with mean 3 and std 1\n",
    "in_stdx = np.asarray(2 * np.random.randn(nb_data) + 1, dtype='float32')\n",
    "in_target = np.asarray(1.5 * np.random.randn(nb_data) + 2, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a perfect training set, where we should get perfect results\n",
    "in_meanx = np.ones(nb_data, dtype='float32') * 3\n",
    "in_stdx = np.ones(nb_data, dtype='float32') * 3\n",
    "in_target = np.ones(nb_data, dtype='float32') * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have set up our model and created some simple test data. Let's now initialize the network and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "model = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0; mean_crps = 2.790\n",
      "Step 10; mean_crps = 2.722\n",
      "Step 20; mean_crps = 2.656\n",
      "Step 30; mean_crps = 2.592\n",
      "Step 40; mean_crps = 2.531\n",
      "Step 50; mean_crps = 2.472\n",
      "Step 60; mean_crps = 2.415\n",
      "Step 70; mean_crps = 2.359\n",
      "Step 80; mean_crps = 2.306\n",
      "Step 90; mean_crps = 2.254\n",
      "Step 100; mean_crps = 2.204\n",
      "Step 110; mean_crps = 2.156\n",
      "Step 120; mean_crps = 2.109\n",
      "Step 130; mean_crps = 2.064\n",
      "Step 140; mean_crps = 2.020\n",
      "Step 150; mean_crps = 1.978\n",
      "Step 160; mean_crps = 1.937\n",
      "Step 170; mean_crps = 1.897\n",
      "Step 180; mean_crps = 1.859\n",
      "Step 190; mean_crps = 1.822\n",
      "Step 200; mean_crps = 1.786\n",
      "Step 210; mean_crps = 1.751\n",
      "Step 220; mean_crps = 1.717\n",
      "Step 230; mean_crps = 1.684\n",
      "Step 240; mean_crps = 1.653\n",
      "Step 250; mean_crps = 1.622\n",
      "Step 260; mean_crps = 1.592\n",
      "Step 270; mean_crps = 1.563\n",
      "Step 280; mean_crps = 1.534\n",
      "Step 290; mean_crps = 1.507\n",
      "Step 300; mean_crps = 1.480\n",
      "Step 310; mean_crps = 1.455\n",
      "Step 320; mean_crps = 1.429\n",
      "Step 330; mean_crps = 1.405\n",
      "Step 340; mean_crps = 1.381\n",
      "Step 350; mean_crps = 1.358\n",
      "Step 360; mean_crps = 1.336\n",
      "Step 370; mean_crps = 1.314\n",
      "Step 380; mean_crps = 1.293\n",
      "Step 390; mean_crps = 1.272\n",
      "Step 400; mean_crps = 1.252\n",
      "Step 410; mean_crps = 1.232\n",
      "Step 420; mean_crps = 1.213\n",
      "Step 430; mean_crps = 1.194\n",
      "Step 440; mean_crps = 1.176\n",
      "Step 450; mean_crps = 1.158\n",
      "Step 460; mean_crps = 1.141\n",
      "Step 470; mean_crps = 1.124\n",
      "Step 480; mean_crps = 1.108\n",
      "Step 490; mean_crps = 1.092\n"
     ]
    }
   ],
   "source": [
    "# Let's run over the data a few times and print out the crps every few steps\n",
    "# Note that this is simply gradient descent, not stochastic, since\n",
    "# we are giving the algorithm all the data for each update/\n",
    "lr = np.asarray(0.001, dtype='float32')\n",
    "for i in range(500):\n",
    "    cost = model.train(in_meanx, in_stdx, in_target, lr)\n",
    "    if i%10 == 0: print('Step %i; mean_crps = %.3f' % (i, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(in_meanx, in_stdx, in_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41526058,  0.41526058,  0.41526058,  0.41526058,  0.41526058])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good so far, we are able to reduce the CRPS and also get the correct predictions where possible. So now we can actually start thinking about real data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's load some real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy this from the python_data_handling notebook. \n",
    "# Eventually this function will go in a separate file\n",
    "from netCDF4 import Dataset\n",
    "# Define directory where interpolated files are stored.\n",
    "# DATA_DIR = '/project/meteo/w2w/C7/ppnn_data/'   # At LMU\n",
    "DATA_DIR = '/Users/stephanrasp/repositories/ppnn/data/'  # Mac\n",
    "# Define file name\n",
    "fn = 'data_interpolated.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rg = Dataset(DATA_DIR + 'data_interpolated.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from netCDF4 import num2date\n",
    "def get_data_slice(rg, month, utc=0):\n",
    "    # Get array of datetime objects\n",
    "    dates = num2date(rg.variables['time'][:],\n",
    "                     units='seconds since 1970-01-01 00:00 UTC')\n",
    "    # Extract months and hours\n",
    "    months = np.array([d.month for d in list(dates)])\n",
    "    hours = np.array([d.hour for d in list(dates)])\n",
    "    \n",
    "    # for now I need to include the Kelvin fix\n",
    "    tfc = rg.variables['t2m_fc'][:]\n",
    "    idx = np.where(np.mean(tfc, axis=(1, 2)) > 100)[0][0]\n",
    "    tfc[idx:] = tfc[idx:] - 273.15\n",
    "    \n",
    "    # Extract the requested data\n",
    "    tobs = rg.variables['t2m_obs'][(months == 1) & (hours == 0)]\n",
    "    tfc = tfc[(months == 1) & (hours == 0)]\n",
    "    return tobs, tfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's load the data for all of Jan for 00UTC init\n",
    "tobs, tfc = get_data_slice(rg, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we have to compute the mean and std for the ensemble\n",
    "tfc_mean = np.mean(tfc, axis=1, dtype='float32')\n",
    "tfc_std = np.std(tfc, axis=1, ddof=1, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 537)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfc_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 537)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten to 1D\n",
    "tobs = np.ravel(np.asarray(tobs, dtype='float32'))\n",
    "tfc_mean = np.ravel(tfc_mean)\n",
    "tfc_std = np.ravel(tfc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166470,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14361"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(tobs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out nans\n",
    "mask = np.isfinite(tobs)\n",
    "tobs = tobs[mask]\n",
    "tfc_mean = tfc_mean[mask]\n",
    "tfc_std = tfc_std[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the 1D arrays we need. Time to feed them to the learning network and learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "model = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's first check what our CRPS is without training\n",
    "from scipy.stats import norm\n",
    "def crps_normal(mu, sigma, y):\n",
    "    loc = (y - mu) / sigma\n",
    "    crps = sigma * (loc * (2 * norm.cdf(loc) - 1) + \n",
    "                    2 * norm.pdf(loc) - 1. / np.sqrt(np.pi))\n",
    "    return crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.35477760093263"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crps_normal(tfc_mean, tfc_std, tobs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's try training.\n",
    "1. Gradient descent with all data and a learning rate of 0.1. Still learning after 500 steps. So after around 2000 steps we get a CRPS of around 1.113 which is lower than the EMOS global for Jan, but of course this is not a fair comparison.\n",
    "2. Can we use a much higher learning rate with standard gradient descent? Try 0.5. Doesn't seem like it is working very well. Yes, 0.1 is much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Were still masked arrays\n",
    "tfc_mean = np.asarray(tfc_mean, dtype='float32')\n",
    "tfc_std = np.asarray(tfc_std, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0; mean_crps = 2.967\n",
      "Step 100; mean_crps = 1.117\n",
      "Step 200; mean_crps = 1.115\n",
      "Step 300; mean_crps = 1.115\n",
      "Step 400; mean_crps = 1.114\n",
      "Step 500; mean_crps = 1.114\n",
      "Step 600; mean_crps = 1.114\n",
      "Step 700; mean_crps = 1.114\n",
      "Step 800; mean_crps = 1.114\n",
      "Step 900; mean_crps = 1.114\n"
     ]
    }
   ],
   "source": [
    "# Let's train. Try gradient descent with all data at once\n",
    "lr = np.asarray(0.1, dtype='float32')\n",
    "for i in range(1000):\n",
    "    cost = model.train(tfc_mean, tfc_std, tobs, lr)\n",
    "    if i%100 == 0: print('Step %i; mean_crps = %.3f' % (i, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 t2m_obs(time, station)\n",
       "    units: deg_C\n",
       "    _FillValue: nan\n",
       "    long_name: t2m station observation\n",
       "unlimited dimensions: \n",
       "current shape = (7306, 537)\n",
       "filling on"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the next step would be to update the data handling function to return the \n",
    "# data from the last 25 days\n",
    "rg.variables['t2m_obs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rolling_slice(rg, date_idx, window_size=25, utc=0):\n",
    "    \"\"\"\n",
    "    Return the forecast and observation data from the \n",
    "    previous *window_size* days. So if date_idx=10 and \n",
    "    window_size=3, it would get the data for indices 7, 8, 9.\n",
    "    \"\"\"\n",
    "    # Get array of datetime objects\n",
    "    dates = num2date(rg.variables['time'][:],\n",
    "                     units='seconds since 1970-01-01 00:00 UTC')\n",
    "    # Extract months and hours\n",
    "    months = np.array([d.month for d in list(dates)])\n",
    "    hours = np.array([d.hour for d in list(dates)])\n",
    "    \n",
    "    # for now I need to include the Kelvin fix\n",
    "    tfc = rg.variables['t2m_fc'][:]\n",
    "    idx = np.where(np.mean(tfc, axis=(1, 2)) > 100)[0][0]\n",
    "    tfc[idx:] = tfc[idx:] - 273.15\n",
    "    \n",
    "    # Extract the requested data\n",
    "    tobs = rg.variables['t2m_obs'][(hours == utc)]\n",
    "    tfc = tfc[(hours == utc)]\n",
    "    \n",
    "    # Get the correct indices\n",
    "    idx_start = date_idx - window_size\n",
    "    idx_stop = date_idx\n",
    "    \n",
    "    # Get the slice for the indices\n",
    "    tobs = tobs[idx_start:idx_stop]\n",
    "    tfc = tfc[idx_start:idx_stop]\n",
    "    \n",
    "    return tobs, tfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobs_roll, tfc_roll = get_rolling_slice(rg, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 50, 537)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfc_roll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function compute means and std and flatten\n",
    "def prep_data(tobs, tfc):\n",
    "    ax = 0 if tobs.ndim == 1 else 1\n",
    "    # Compute mean and std and convert to float32\n",
    "    tfc_mean = np.mean(np.asarray(tfc, dtype='float32'), axis=ax)\n",
    "    tfc_std = np.std(np.asarray(tfc, dtype='float32'), axis=ax, ddof=1)\n",
    "    tobs = np.asarray(tobs, dtype='float32')\n",
    "    \n",
    "    # Flatten\n",
    "    tobs = np.ravel(tobs)\n",
    "    tfc_mean = np.ravel(tfc_mean)\n",
    "    tfc_std = np.ravel(tfc_std)\n",
    "    \n",
    "    # Remove NaNs\n",
    "    mask = np.isfinite(tobs)\n",
    "    tobs = tobs[mask]\n",
    "    tfc_mean = tfc_mean[mask]\n",
    "    tfc_std = tfc_std[mask]\n",
    "    \n",
    "    return tobs, tfc_mean, tfc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobs_roll, tfc_mean_roll, tfc_std_roll = prep_data(tobs_roll, tfc_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11308,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfc_mean_roll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's train again.\n",
    "model = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0; mean_crps = 1.047\n",
      "Step 10; mean_crps = 1.046\n",
      "Step 20; mean_crps = 1.045\n",
      "Step 30; mean_crps = 1.044\n",
      "Step 40; mean_crps = 1.044\n",
      "Step 50; mean_crps = 1.044\n",
      "Step 60; mean_crps = 1.043\n",
      "Step 70; mean_crps = 1.043\n",
      "Step 80; mean_crps = 1.043\n",
      "Step 90; mean_crps = 1.043\n"
     ]
    }
   ],
   "source": [
    "lr = np.asarray(0.1, dtype='float32')\n",
    "for i in range(100):\n",
    "    cost = model.train(tfc_mean_roll, tfc_std_roll, tobs_roll, lr)\n",
    "    if i%10 == 0: print('Step %i; mean_crps = %.3f' % (i, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems to take max 200 steps to find the minimum. Time to actually loop over all the dates and compute the actual score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's actually modify the slicing function and feed it the full data.\n",
    "# Because something took quite long earlier...\n",
    "tobs_full = rg.variables['t2m_obs'][:]\n",
    "tfc_full = rg.variables['t2m_fc'][:]\n",
    "dates = num2date(rg.variables['time'][:],\n",
    "                     units='seconds since 1970-01-01 00:00 UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = np.array([d.month for d in list(dates)])\n",
    "hours = np.array([d.hour for d in list(dates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.where(np.mean(tfc_full, axis=(1, 2)) > 100)[0][0]\n",
    "tfc_full[idx:] = tfc_full[idx:] - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can also alread get all the 00UTC data\n",
    "tfc_full = tfc_full[hours == 0]\n",
    "tobs_full = tobs_full[hours == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rolling_slice(tobs_full, tfc_full, date_idx, window_size=25, \n",
    "                      fclt=48):\n",
    "    \"\"\"\n",
    "    Return the forecast and observation data from the \n",
    "    previous *window_size* days. So if date_idx=10 and \n",
    "    window_size=3, it would get the data for indices 7, 8, 9.\n",
    "    Nope, also have to go back the forecast lead time.\n",
    "    \"\"\"\n",
    "    fclt_didx = int(fclt / 24)\n",
    "    \n",
    "    # Get the correct indices\n",
    "    idx_start = date_idx - window_size - fclt_didx\n",
    "    idx_stop = date_idx - fclt_didx\n",
    "    \n",
    "    # Get the slice for the indices\n",
    "    tobs_roll = tobs_full[idx_start:idx_stop]\n",
    "    tfc_roll = tfc_full[idx_start:idx_stop]\n",
    "    \n",
    "    return tobs_roll, tfc_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_00 = dates[hours == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3653,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_00.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do it fully for the first time step with predicting the current date\n",
    "date_idx = 100\n",
    "window_size = 50\n",
    "tobs_roll, tfc_roll = get_rolling_slice(tobs_full, tfc_full, date_idx, \n",
    "                                        window_size)\n",
    "tobs_date, tfc_date = (tobs_full[date_idx], tfc_full[date_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobs_date.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tobs_roll, tfc_mean_roll, tfc_std_roll = prep_data(tobs_roll, tfc_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobs_date, tfc_mean_date, tfc_std_date = prep_data(tobs_date, tfc_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.69999981,  2.5999999 ,  3.0999999 , ...,  8.30000019,\n",
       "        9.80000019,  6.30000019], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tobs_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0; mean_crps = 4.321\n",
      "Step 10; mean_crps = 1.171\n",
      "Step 20; mean_crps = 1.146\n",
      "Step 30; mean_crps = 1.126\n",
      "Step 40; mean_crps = 1.111\n",
      "Step 50; mean_crps = 1.100\n",
      "Step 60; mean_crps = 1.092\n",
      "Step 70; mean_crps = 1.087\n",
      "Step 80; mean_crps = 1.083\n",
      "Step 90; mean_crps = 1.081\n",
      "Step 100; mean_crps = 1.080\n",
      "Step 110; mean_crps = 1.079\n",
      "Step 120; mean_crps = 1.078\n",
      "Step 130; mean_crps = 1.078\n",
      "Step 140; mean_crps = 1.077\n",
      "Step 150; mean_crps = 1.077\n",
      "Step 160; mean_crps = 1.077\n",
      "Step 170; mean_crps = 1.077\n",
      "Step 180; mean_crps = 1.077\n",
      "Step 190; mean_crps = 1.077\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    cost = model.train(tfc_mean_roll, tfc_std_roll, tobs_roll, lr)\n",
    "    if i%10 == 0: print('Step %i; mean_crps = %.3f' % (i, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.253791908507415)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now make a prediction for the actual day\n",
    "model.predict(tfc_mean_date, tfc_std_date, tobs_date)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2007, 1, 28, 0, 0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_00[date_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([363]),)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "np.where(dates_00 == datetime.datetime(2008, 1, 1, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3650]),)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dates_00 == datetime.datetime(2016, 12, 31, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-02-07 00:00:00\n",
      "2008-03-28 00:00:00\n",
      "2008-05-17 00:00:00\n",
      "2008-07-06 00:00:00\n",
      "2008-08-25 00:00:00\n",
      "2008-10-14 00:00:00\n",
      "2008-12-03 00:00:00\n",
      "2009-01-22 00:00:00\n",
      "2009-03-13 00:00:00\n",
      "2009-05-02 00:00:00\n",
      "2009-06-21 00:00:00\n",
      "2009-08-10 00:00:00\n",
      "2009-09-29 00:00:00\n",
      "2009-11-18 00:00:00\n",
      "2010-01-07 00:00:00\n",
      "2010-02-26 00:00:00\n",
      "2010-04-17 00:00:00\n",
      "2010-06-06 00:00:00\n",
      "2010-07-26 00:00:00\n",
      "2010-09-14 00:00:00\n",
      "2010-11-03 00:00:00\n",
      "2010-12-23 00:00:00\n",
      "2011-02-11 00:00:00\n",
      "2011-04-02 00:00:00\n",
      "2011-05-22 00:00:00\n",
      "2011-07-11 00:00:00\n",
      "2011-08-30 00:00:00\n",
      "2011-10-19 00:00:00\n",
      "2011-12-08 00:00:00\n",
      "2012-01-27 00:00:00\n",
      "2012-03-17 00:00:00\n",
      "2012-05-06 00:00:00\n",
      "2012-06-25 00:00:00\n",
      "2012-08-14 00:00:00\n",
      "2012-10-03 00:00:00\n",
      "2012-11-22 00:00:00\n",
      "2013-01-11 00:00:00\n",
      "2013-03-02 00:00:00\n",
      "2013-04-21 00:00:00\n",
      "2013-06-10 00:00:00\n",
      "2013-07-30 00:00:00\n",
      "2013-09-18 00:00:00\n",
      "2013-11-07 00:00:00\n",
      "2013-12-27 00:00:00\n",
      "2014-02-15 00:00:00\n",
      "2014-04-06 00:00:00\n",
      "2014-05-26 00:00:00\n",
      "2014-07-15 00:00:00\n",
      "2014-09-03 00:00:00\n",
      "2014-10-23 00:00:00\n",
      "2014-12-12 00:00:00\n",
      "2015-01-31 00:00:00\n",
      "2015-03-22 00:00:00\n",
      "2015-05-11 00:00:00\n",
      "2015-06-30 00:00:00\n",
      "2015-08-19 00:00:00\n",
      "2015-10-08 00:00:00\n",
      "2015-11-27 00:00:00\n",
      "2016-01-16 00:00:00\n",
      "2016-03-06 00:00:00\n",
      "2016-04-25 00:00:00\n",
      "2016-06-14 00:00:00\n",
      "2016-08-03 00:00:00\n",
      "2016-09-22 00:00:00\n",
      "2016-11-11 00:00:00\n",
      "2016-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Now let's actually loop\n",
    "crps_train_list = []\n",
    "crps_predict_list = []\n",
    "lr = np.asarray(0.1, dtype='float32')\n",
    "window_size = 50\n",
    "for date_idx in range(363, 3651):   # Just try 50 days\n",
    "    if date_idx % 50 == 0:\n",
    "        print(dates_00[date_idx])\n",
    "    tobs_roll, tfc_roll = get_rolling_slice(tobs_full, tfc_full, date_idx, \n",
    "                                            window_size)\n",
    "    tobs_date, tfc_date = (tobs_full[date_idx], tfc_full[date_idx])\n",
    "    tobs_roll, tfc_mean_roll, tfc_std_roll = prep_data(tobs_roll, tfc_roll)\n",
    "    tobs_date, tfc_mean_date, tfc_std_date = prep_data(tobs_date, tfc_date)\n",
    "    \n",
    "    model = EMOS_Network()\n",
    "    for i in range(200):\n",
    "        cost = model.train(tfc_mean_roll, tfc_std_roll, tobs_roll, lr)\n",
    "    crps_train_list.append(cost)\n",
    "    \n",
    "    crps_pred = model.predict(tfc_mean_date, tfc_std_date, tobs_date)[2]\n",
    "    crps_predict_list.append(crps_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the data. Its past midingt and I can't be bothered to save them anywhere useful...\n",
    "np.save('./EMOS_network_crps_train.npy', crps_train_list)\n",
    "np.save('./EMOS_network_crps_predict.npy', crps_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXm4HEXV/79nZu6S3OzkkoQESFhkkSVC2DfZVwEBBV7x\nJcIrr+LGq6gs70+DiKisKspLBALKpmwiIAiELWyBG8hKAiEbSchys919nanfH90z09PTS/VMd3XN\n3PN5nvvcmd7qTHXV6dOnTp0iIQQYhmGYyiERtwAMwzBMMFhxMwzDVBisuBmGYSoMVtwMwzAVBitu\nhmGYCoMVN8MwTIXBipthGKbCYMXNMAxTYbDiZhiGqTBSUVx09OjRYuLEiVFcmmEYpiqZM2fOJiFE\no8yxkSjuiRMnoqmpKYpLMwzDVCVEtEr2WHaVMAzDVBhSipuI/oeIFhHRQiJ6mIjqoxaMYRiGccZX\ncRPReADfBzBFCLEPgCSAC6IWjGEYhnFG1lWSAjCIiFIABgP4LDqRGIZhGC98FbcQYi2AmwF8CmAd\ngBYhxAv244joMiJqIqKm5ubm8CVlGIZhAMi5SkYCOAvAJAA7AGggoovsxwkhpgshpgghpjQ2SkW0\nMAzDMCUg4yo5AcAKIUSzEKIPwBMADo9WLIZhGMYNGcX9KYBDiWgwERGA4wEsjlYsJjQyGeCDB4B0\nX9ySMAwTEjI+7tkAHgPwPoAF5jnTI5aLCYuFjwFPfQd447a4JWEYJiSkZk4KIX4O4OcRy8JEQddW\n43/7xnjlYBgmNHjmZNVDcQvAMEzIsOJmGIapMFhxMwzDVBisuAcMIm4BGIYJCVbc1Q6ZPm7Bipth\nqgVW3AzDMBUGK26GYZgKgxU3wzBMhcGKm2EYpsJgxc0wDFNhsOIeMHBUCcNUC6y4qx0OB2SYqoMV\nN8MwTIXBipthGKbCYMVd9XB2QIapNlhxMwzDVBisuAcMPDjJMNUCK+5qh9hVwjDVhq/iJqI9iGiu\n5a+ViK5QIRwTIhwOyDBVg++ak0KIjwBMBgAiSgJYC+DJiOViGIZhXAjqKjkewDIhxKoohGEYhmH8\nCaq4LwDwsNMOIrqMiJqIqKm5ubl8yZiQyPq42VXCMNWCtOImoloAZwJ41Gm/EGK6EGKKEGJKY2Nj\nWPIx5cKDkwxTdQSxuE8F8L4QYkNUwjAMM8Dp7wVm3wWk++OWRGuCKO4L4eImYRiGCYXXfgM89xNg\n0RNxS6I1UoqbiBoAnAiAa7NS4XBAphJo/cz4P+tW4Plr4pVFY6QUtxCiQwixnRCiJWqBmLBhHzdT\nSZgGRvNi4J0/xiuKxvDMyWqnvyduCRhGHn4zlIIVd7Xz3I+N/1tXxioGw8jBilsGVtwDha5tcUvA\nMP6wxS0FK26GYZgKgxU3wzAawRa3DKy4GSYutiwHZl7P7gErXBdSsOIeMHCH0I6Hzgdm3QxsXRG3\nJBrB7VQGVtwDBo7n1g4O1SxGJ4u7twN48KtaRmSx4maY2OGHah6NFPfHzwNL/w28NC1uSYpgxT1g\n0KhDMCZ8T4rQyeLWGFbcDBM3nHrXAituGVhxMwyjD2xxS8GKm2HignVUMSITtwTFaPgwYcXNMLGR\nVQjsKtETfe8LK26GYfRBQ+tWR1hxMwyjEay4ZWDFPVBgS0Y/sveEo0ryaNlO9ZOJFTfDxA4r7jz6\nKUkdkV1zcgQRPUZES4hoMREdFrVgDFP9sJIqQkuLW78Hq6zF/TsAzwsh9gSwP4DF0YnEMAOMF66N\nWwKN0FFx60fK7wAiGg7gaABTAUAI0QugN1qxGGYA8eFTcUugD1pa3PrJJGNxTwLQDGAGEX1ARHcT\nUYP9ICK6jIiaiKipubk5dEEZpurQUknFjUZ1ovGgsYziTgE4AMCdQogvAOgAcJX9ICHEdCHEFCHE\nlMbGxpDFZBhmQMAPMyl8XSUA1gBYI4SYbX5/DA6Km9Ed7hDa0fZZ3BLow293BSYdDW6ncvha3EKI\n9QBWE9Ee5qbjAXwYqVQMo4rV7wF93XFLwXRuAhY9oafFraFMslEl3wPwIBHNBzAZwK+iE6lKyaSB\n/jjHdDXz1/X3GiuMxMmWFcA9JwD/ujJeOZg8y1+Jr+xNS4Hlr1o2aNZnLMi4SiCEmAtgSsSyVDcP\nXwAsfQGY1hKTAJpZDTNOAdbOibE+AHRvM/6vmxefDIw+3GGquFyb1KzPWOCZk6pY+kK85Wdf99bN\nA1a+Ga8sgKG0GaYS0DC6RMriZqqIu442/sdp6WqDfh2S0ZAK9nEzTDRsWx23BND5lZiJE/PBvvif\nwIpZ8YpigxX3QEHD1z0Aeq54wjB27j8jbgkKYMXNxAtxE2SYoFR3rxFCS/8UYyHON4Fs2dxEmHXz\n45YgENWruHs7getGAK/9Nm5J9EDbB1icLhxN3Ucq6WkHPvsgbiniZeUbwF1HFW/X1b2Ialbc3WbU\nRNM98cqhDZoqbo07x4DgsW8A079oKHANae/pj76QrSvljtPI+KlexZ2DFQMAoHlJ3BK4ENP96esC\nMn3mF306pHKy8fTv3Q08fUW8sjjw6ebO+Aq3K2pW3CrQoJKbPwKub5R/og9E4rK4bxgL3H1CPGXr\nRMKcyvHSz4E5M+KVxQGhQz/OolEEVPUq7iXPxi0B8MFfgXQvsOgfcUuiMTG+EWnUEWMjURO3BJ70\n9sd4j4qMCn0eItWruLVIHKSxmybO174Vr+c/s4/bIK77kUjGU64knb1p9YWufg+488jirJEaPeir\nV3FnYcWgH63rLF80uD86+C5ZcTvSoWJw0s5zPwE2LADWvFu4nRW3QtrWAXMfilsK/dBBWQHAzbsB\nCx6LWQgd6iImGUhvxa3G4nYxHuxph3XpM6hGxd3XBaRtT+l/fDvm3M/63HA9sNXH84oXVJr3N7Xl\nyRCXUtB85mpHbwwW92fvG/+Lokr0sbirLzvgDWOBXY8v3r5uPjBqF2DoGHWyaO2mifFhUtQBFNfT\nJy+qLU8KVtxOdPbE4ON2RR8DTO+7VirLZhZvm3EK8PvJ6mVh9MNuSfX3xCOHFba4HYnF4s6hr8Wt\n910Lm74Yg/mz6JITIU5/nUa+QgBGyGbcZPqBacOB+89UW65dcevwELMQS1RJFruirjTFTUQriWgB\nEc0loqaohao6rIrqrqMMPzwTH3YX1qhJ8chhZb35QF/xmtpy7XXRulZt+T7EElXihkYGRxAf97FC\niE2RSVKVuPhu031AzSC1ohQRZyO0lR33WEDLmnjLB/RxlcQhh8cENSUWt2z700hxDyxXCcMAxR1w\ny/J45ChAE8WtmrYNwKMXu+6O1eLu3Fz4vdJcJTBa1UtENIeILotSICZCNi7Of9bKx61z9E1E6GK9\n2SfgqH77SXv71GP1cS972bZBk3sGeVfJkUKItUS0PYAXiWiJEOJ16wGmQr8MAHbaaaeQxax07Dc8\npgbwp0PjKbcIfTpAbNgVd9e2eOSwPzRVP1B8yos3qsRGpVncQoi15v+NAJ4EcLDDMdOFEFOEEFMa\nGxvDlbJScbNetLC2NLK4VVt5TuUpz+Boq4NHLlRcvkncrhIfHtp4DrBhUdxiGFSS4iaiBiIamv0M\n4CQAC6MWrKrY8KFtg4/SXP4qcMMO+cUgqonOLeo7YrofeOo7eV+204Nz0ydqZdKF2HOVePeFQegG\nmu5VJIsPWhhcBjKukjEAniTDSkkBeEgI8XykUlUbCwPm4nj110Bfh6Hgdj48GpniaoR3HQ20rLZt\njNjiXvMu8MEDwOZlwCVuTVcvF4EyNLe4AehTVxpZ3L6KWwixHMD+CmQZOOjSEOOgSGlrgvJ7okkb\nsLuNVNeD1JJpmtSVRoq7Ah63lUyJlqS183RuiWTCTnvb1tCvWTJxx3ED0Mni7k8rVBBFcdyKozhm\n3+l7SCbyh4ls+9PkAQJW3PEg/eQm4LeTgLuOCV2E1e88Efo1mSC4K4GVmxVmsrQp7mUbW9WVDUhZ\n+EofZF6wxT3ACWpBbPoodBFmvLki9Gtqi0x9axQGt7FNYb4Qm+K+/IEmzFsdV2iiM/0ZPSzd2cv1\nmTjOijsWFDbEPU5z3DxxVNxT7mOgeQlw3xnOrqeHzwfWL1AojHsb6OmLz1WSRAYfrW9TV74EWzv0\nSHx11eOaJIgDK+5ocfHdioxCP6KLZdc4pE6dDHGTvQ9dW4GVs4BP33I+7tVfq5PJw+Lu6lPYPmyK\nmyBw/bP28NV4mfWxHpbuDqSHHAAr7lh45L1PfY6I3iJPZ/Tx10UeDig7xV7pIKmH4lY5zdumuEdR\nG/YeoVPbADKa+JYfrL0RmPdI3GIAqGbF3bB93BK48uqSDXGLgP60TiuLKMY1ckKh4n7sEtddcVrc\nf639Nf627QJ15esQGhvkgb3K5W1NMdWruN0sGg2mzw6pUzlbzbketBmpB9SHA7rNSFUpx8fuc9i6\nlSpuHUIxvdFKQtXhki5Ul+Je+37+s9uTXGlOCucmN3ZYreTp0TVZpa6SOfcBn85WV17J6KEi1Cru\n6lIBkaOJi7G6FgteNzf/2cUv1tXbDyXxFC//Eph1s+Oube0Kl8pyeYAptbif/oHxf5pb7hU9FKYu\n1qdaV0ncuUr8SZBAfzqDVFKDhwxb3BFQoKydFdazC9apkeX1m1x3be1UGd6kgeKuGDRR3L0xzpxU\njr+PO4V+tHT1KZDFn3mrt8QtAoCqU9yWRtDlPKV78ToFM8Pamz13b8nGpa6Z42wRhzlg43ItraJK\n9NCXGigxgzgHJ3PMulWdDD4QgLZuPfJyf7pJjxh3PVpqWEiEDaVVzMLavNRzd3NrF9KLngLuPg6Y\n+6DHkWFoNBfFzRZ3EWkNAhwAoKdfA8U98zp1MvhAEOjVpL3qYmMMOMVdX6PgJye8hw7SmQw6PjOn\nsTeHP529AJ0s7n9c7rJDj+4w6xM9Jlj09A8gV4nE2yVBRDubNFCcuB5P9wGnuMcMVTBj0Cc5PQHo\nVZZ/QSPF7fl2ET+bO/V4HY9zyruOJCDQG+W8gwCuSWLFHQESirtPxfuwz0h9Ahm0dSlSEkULnhpo\n5SohMiY2LH8tbkFiLt+gp0/hA0STSJoCkoXhsomoLe4AypigyN3qw4BT3KJfQUSHj6sEAOasyg6e\nOjWCkBqGx3Jc6UwGQodZa1lmnAr85cyILi73O4UmirtXlY971VvAmiY1Zbnh9OD4f83AkT/MH4JM\ntO6jAK4SgtBiAeMBp7i/vum26OXwUdwEgSGDaqKXY84Mj51CzduHFHoozIzQQw5linvGqUDzYjVl\nubHbCb6HJCEiVtzB+kG7BhEu0oqbiJJE9AERPROlQGUhcQMGi87o5fBR3GeM+gzbOs241Cit3knu\nCzAQFEcveKLHCieRW9z9PcC04cB7d3se1qvSVRI3bn3FYokTRLRtNZDFjXzfjZEgFvcPAMT8ePZB\nkyxiflzRcTtqOiQmApXrf/QYJKWorRitkHsw1NVEPIuwy1ygwCd9rDKLWwck+mwi8rYabHBya6fC\nmc8uSCluIpoA4HQA3qZC3Gjjs/WX49w+FS8u7nJopbiV5o9xR91KK94P5AFlcbu2UavFnUFvlG11\n8dPShxIENndUiOIGcDuAnwDQpKe7oEkeAax+N24JfCEg2s5QgfRnoMWAbZ9ii7slNdp5x7p50Rcu\nUd+RW9wukVdO1KIfLZVgcRPRGQA2CiHm+Bx3GRE1EVFTc7P3lO/IULmyjBdPuU00kSQ05eFu2UXu\nN6xAMgLYEqk1JXdfe/rVWtwZt3Zy19FK5SgkX1cZkDZtNYk0OlUudOGCjMV9BIAziWglgEcAHEdE\nD9gPEkJMF0JMEUJMaWxsDFlMWeK3lgITpYXnYUkQFE/0qAAyIC38l6ot7nScwWVu7X/WLflDQNq8\nHRKE2lwyLvjeMSHE1UKICUKIiQAuAPCyEOKiyCUrhQoZnFTG23e47tLKx60JAoTfz3SPfS+/AFNJ\n+bTTTCaDPoUTpNIizqhgCVcJKU4D4EGSFCcBc2HAxXEDevgx83jJEl14WisGa2PF6IIAYdggBSnq\nLdFC/04fVLQ7AaF0MYUhGQUZM91w64tf+n3uI1FCm7fDVELxmqAuBFLcQohXhRBnRCVM2Ugqbl0y\njcVJsxiujd9QFzIgtEaaiqBYSf0h+TXH47oVKqoG0aGsrCLc+myqPveRSB8fd4pE5Slu7ZFU3Lq8\ndgFwsTiifyOIPja28uhDKtrskQ73urdmJDD+wIJtqi3ueHFp65Y5COlEjVLXkRcpEujU4N5UmeKW\nHLXX5LUrTpRFlQR1S6Xji2Gura33PygMLHVSX5cCxk0u2E0Q+HiDHgn7I8etfSTzKSGWJXdR6tZb\nI1zCIwHUJgU2t6tcwcqZAam4B4414w5B0RJZQRV3073RyCFDqkZRqFe+TgbX1sBudSYgkNAxa18k\nuFnc+bGGFAmlIXiphLtarCGBjp749UeVKW65CtXLReCh2CLsvAlk0N6jIOdC0Eif3vYIZJB8eCTr\nlPsv62uLB0MjdZX0tBn5Uj7IR/Te139SNGXJ4HZvEnmLe2tHL174cIMigYCh9e4D1AnSY+JalSlu\nuQpli9t4JqjJcqZTBI83lKqLOGVncV0MrqtxUF4Rxgq3rDX+v5mP2hhB7WitHx9Neb74+7iTiids\ne73tEJEWwQ3Vo7j7e4F3p0sdqpXFHVNo4uAaQqsKxR3490VQH5JvLv/Z9mecsu3v4ZefxaEuBtUW\np/dNRBlVkjVuLHVydvItPPXF56IpT1YeOxYf9//UPK5IGIOEZ3PRYzJQ9SjuAK/YPbpb3FEq812P\nBwAMSiXQ3qNCccffyIMwtVOtj31wXfFrOUUaVZJtW4XaqaE24syIbri6ShTE07vgpbgpwRZ3bOiQ\nayCPYov79JsBAINqSE9XiVaTo8LGyeKuLdqegEB3VBE/2fq1rTU52MHXrgaX+22Try6lTlWlx+5f\nuGHqs7mPxBZ3fOiw9FAW5Yv2mh1iUE0CbUoGJzVQxEFXOIn6TcQiz6D6YlcJRToBJ6u4C83KwbpZ\n3LbtKhV3jTUsdMw+wMQjc19b63dgxR0XkYbzzJbzs2dRnzTf6LCDUoos7gpzlQDAprao43TzSmmI\ng6ukPkXRuUqEi6ukLibF7fpGVrhdpYGT9PCVdNeOZFdJXHREaVE99+NAhysdKD36xzmL+4SOZ5Hp\n3qag0GDWrvI3EAc2RTXBwnFwsrZo+0k1c9EZ1dtQbnCycLObqyTyGYuSFrdQaQAUlF1YUUkyVnmP\ne6X36lHcTg2gfrjjoTq5SpwtbmerqGwGb5d7RZ7YswQ/6rg93Os7EdBNsbk9/rSqzVFb3N35pE4N\nDjHDPxX34oD1j0VUuNvgpLPiXretG/jouehWKZJsH5RR2WfdZUqRsS/uKfjVo7idKnvX4/KfLYMd\nkVrcAVHrLyNYO2xjemP0RQa0lDTwiGNTW1dEV86mdc0/rN0U5l6tsyISwZRh/fyCzYMcfNztoh6t\n3X3AwxcAfzwkGnkkXSVCqeJ2J2kq7rhDiqtIcftw5h9yHzsijSoJZiV3K1pfsGfnLwL7X1DwAKtF\nP2Yv3xxxycFUcX86/oifvRf8VllZDXUpONVRZK/iLhauk487iQy62s23g/7uaOR5+Qbn7TY5kyKD\njCr3hLXsr95fKIepuOMeoKwexe3UIK3bLGkiI7W43VZWH7sfcNSVRZvfXbbJ/Vohekp6L3wMGDSi\nIJpg98RavLwkYqs7oKukLx2/zb3Phn9Ec2GHumhwGJwEIlTcDg+JRbS74eM+4OKC7YOoFwc9vE9E\ncpj0tEgdlkQa6TgilLbbtVAOs/vEPUBZPYrbjan/Ai6fXbAp0qgScqnSM24HRuxYfLgi50B9jflA\nscmX2x4VATtbvwYj9ir1Q0Nt0rHNRGZdOriufjv6l8aHfc7JbWvZ68Joyrdz+PdcdhT+/hQyCgcE\n3cvJKu6402ZUkeJ2yWs98Qhg+z0LtkZqcaddBtfGHwCM3bdosyrFXZPM3upCM35b5GssBlTcGkSV\nqMz6O7guBRz3M2D8lILtKq3L11YX94dUTa2awiWjSvZNLEd/zJEcgBGqCUS9qLQ/VaS4fbC4CDpV\nR5VcvcYof/yBwA4HFOzK+swKiLLT2qy7rZ0RT8J5+fpAh+tgcQNRWVTF93VIbQpo2A745kzg5F/l\ntmeiCn9zbFvFPrlU3eBoyrcj+Ttn1N6E7u6I/Ox2PPpfKmHsi3v2ta/iJqJ6InqXiOYR0SIiuk6F\nYIHx83Fb6O9uA5RadpaOMXhUwZ4Rg4pnzkUrSmEn7eiIII2qlTn3BTo8FsV9xcKCrwLqwr0GWwcF\nLalMVbpK/nbZoYUbJh6FmpSiCTkZNwVY/PsTb/3e4bgo8AoHNP7HvXyZjMXdA+A4IcT+ACYDOIWI\nDvU5JwbkG/qz7RcAvxgJbFsdoTwWUu4rq2RcG25E2BR3e2dUoW+lEYvvcOjYok2RDJI6GBJ5F1Yh\n6UxUD7FCGT7M7IzGoXXmrvx0+ITbIHvo4rj8Roe6Em3rIxbGn2wct/Y+bmGQNctqzL/4nU12ev0W\nPHUI0XhdUdhX0j2BT8bL8o+klgvrobUr/mWYrKhcJDdPYZ0Mo654LH/bQ7WlKwI3lk0hLsxMdIhs\nIaBPlVvCrZ6dQiQVKUsPV0nWtRlZvnRJpHzcRJQkorkANgJ4UQgx2+8cpXRtBf5wgMMO/Z4vdpQ1\nxiw2H3drV/wzFa30yMS1L3jMWMWlL4S3hR0OcMzXHUm4V8Cxi0jGHxwUpdPkG7R9Fn7ZTritWjXx\nqKJN/RqEiuYUdwW4SiCESAshJgOYAOBgIioK7iSiy4ioiYiampubw5bTm6e+67zd4jN0TqavYF2/\n/3698Lut82YcFUS4DfS2Edfkv9gUd2d3b3TWpZdidQmblHoFnWkOs7TLLmflUp+NewJTn4FTO4hG\nSchfkyCwNZKIn0IZCAKDnUJC3cJaQxfHfyGFLL06Ke5KsLizCCG2AXgFwCkO+6YLIaYIIaY0NjaG\nJZ8cS55x3n7aTWrlcKLGb3TeK2l+OA11/tCj819qGwr2TU4si+aVHABuKPYdAwAOvsz1FKmQr7D6\n786HF9VHlthzUZBAZ/NK483i4xfCu7BNUSYShFTOz26pWFI1OGmR59tvAd//wPXQbR2K3Hoeb0YJ\nZEBUAT5uImokohHm50EATgSwJGrByma/84GG0d7HhL0Yb7fTLDDvMhIQ2Ob2ShxSWGCtNZex7TfP\nqL0J61oU+TOzHPlDuNWLUt/yyTca/x3agarBSS+OefZY40PAkEpXMhngpWkFm1JOKUyJ3GcAh431\nQTJyEjBqF9dD456tCACUSWNQTbIiXCXjALxCRPMBvAfDx+1i4g5wlr1SvK1IKRQvDBu1xe03O7Jj\nxXuhlCNNIgXsdoLjLilLN6znbY0Z7eOouKOP6PAikolZGxYAnxVatAW5p7PuEXKezRkqHZuBN24H\nrMmj7GVe8xlw7j25r5E81Fe95bDRo+4z/Ybijtni9l2vSAgxH8AXFMgSAwp83D5WfQLCPdNYORa3\n5SHip7gPeelc4AvL/N9QwiKZcvRhApL5uBW4OiOZwRngfh6SiOCl1mEgvEBxTzwKOORbwBE/AGaG\nZOW78c/vAR89W7jN3ldqG4C6obmv/f0RTJybcarccf89C7jrKCCTRn1NMqbopzzVO3NyyiUxFCo3\nK81KIiqLe9ETuY91NRLrCYYRoSFLIgWc+htg368U7Qrdqlr9LvDJzMCn9fZb6l4I4P+OBBY+4X6C\nFD73083KjXDBi1TCUmYiadyXYTsAiYhVQ2+bw0Ynt03e6OjqVbDUnhvj9gN2PBRYNhMnYDZ6lK9c\nVUh1Ku5pLcBO9jlCLr68sOjcAqxf6H+cjV6kii3urGVWjsW96u3cR6n1+lSuqp2oAYZPAM69u2hX\nn8zgZJDbds+JwJvBF4wosLgz/cD6BcAT3wx8nQL87qeb4u4PK7qkuPwWt3BQB1nCdR859UeH3295\ngGTiTvm7+h0AwHXdv449H3dcSztXH3efAGxZ5n+crfP2osbj6V2G4t68NPexXmYF77AVt5OroW4Y\n0NPqOfCVllEOKlwlUQxOblvlvd/tHmRisDQdokq2dvZi+6Hus4DLL9Pb4nafHh8yEgaT9lElVcMO\nTm56F9Otpx348/HBLGg3pe2jEFdkxrr7y0JKNFTk497RIWNB2INRfQ4zWS95HvjK/a7+bcDIihd3\nKB4AjFk8o3hjuVE+D1/gvd/tgZaOLinaLqOdwyGdZAl1WTlHJe1kceflULfupP99jtviHjiKe+TO\nxdu6tjofu+otYG0T8NLPyy+3SHHbLe6Uu8VdqqJ447aCr0Wuku12cyqstLKCMGw88PmzfQ+L25oB\ngL3n/cr/oLBxi50Oa9kuh1tcV+OiAhyU6LqWEMdBejsdyvS2uD3TQ4TJCdOMcOJ9znU9hJwME4UM\nHMXtxCK/waYQfOAe1iVgLA/lPkJdojJ9+08FX+tkFksIO5Vsj8Pgk0Rs8EH0cYBQKwVRQQX41NEH\nD7jE8kvi+ECVKFca+SRXTop7fUuIE2C2rpA7LqHYVXLOn4Ht9wLOmQ6cd6/rYXt0zYteFg8GtuJ2\nJUQlZre4T78VGDkxvxuZ8C1um+VSLzM4CQCtnxl/YfDBA8XbJGbjHZb8EN29spZVxG8JQQaJ174P\nPPUdI8ytVCYc6Ly9r9P5QRgCE0YMct7hcK9CzWMv65orkCODvq2rgZm/iC5nvaRc7TEvOM6K2wlL\nesty6N7tNGNAzsp2uwI/yD+tI7G4LZZou6iXXJ5MALfuZfyFwdIXi7c5WdxTnwVOLIwZlra4o14l\nxu5T9SovG07ZHlGenie/FcllXSOOHNp+uMpKsm9Z5EhAgJ74JjDrFuNBGSNbO/uiXUnLB1bcjmQ7\naJmv4uc/4BsPmyQni7vMcEBLY8+ApMIBQ19tfs27xducLO6JRwJHfL9gk7yrJHj99I10cUdMOqZ4\nW863HH9yIzSHMCHHoT0lnaa8A46KO1RFJTulfui4/CkQEH1Zd028FjcAbGhVnCrCAituJ7J+yjIt\nbk+F+c1KO5qSAAAfL0lEQVSXARiuktAtbkvjEyA0t/v7JtuiSjRlRbKzSiuIEh5siUlHyh8caFAw\nnLc098tHtSKO/HXbw1xkW1ZBDrMq7gwyUb9lBVDccS5fxorbiSf/2/xQXickr048/kAgkUJtQsj5\nuJscwtPcS859yiCBQ3fZrnD3MT8uOuO1j2RTpJaBpFKTXoi1hE6czMqQlFgMN6u4ZcoRIb2luV4/\nooiK+Y84b3dQYOG6BoLXE0FARK645eQSoFhDAllxe1GG9bQwubfE9ZOoS3glZbc00meukC/c5iqp\ntUcOjJwInHZzwaan56+Tv37EyK+gXUInJgIun120zqQjRVEMXuWVIMs3nivett/54V2/rGsUt/10\nd4gDpEH61rjJAIzxoETnJmPb5k/Ck8WKpMWdRgI9MYatsuKOiJTkNPP6FNDWbbNkhO1/UOyK20kW\nWwM9endFCaYk2OyruMsZAyBg+z2BoWP8Dy3Fxx1EIe18ePG2s+90PjYMiztIfQ3boWjTN9aFmHiq\nZY38saaLLQGB2nbzvHcsIa/pfiNv+au/DkEwufuXRoItbn0p3eKuSUr4cxNJDEoKtHW7+ZfLjyrJ\nIFFscQNFirujx8fHrWryA4CtUVrcQa5VkqukTNzGAaJ2EdjZv3iW55RehwHnUnFbsswJs60m4NIG\n0+YYzhvBc9K4leWHAMU6UYwVtyeldxZHZWmHEqhPAq12iztXfInKkgoV99B6h2n3to7pudbj8teA\nX4wE1swpTZ6AXDX/FODRqR5HmL+vpPpxuacphxwcpQxORoVqxV0/HLhiQdHmWJSVn+KOoCw/jPkX\nbHHrSRmdpSYlZ3HXJR1cJWWXn1fcghKWpamsAg4Cjr0297XLK7/wJy8Z/1e+7n5MiDRk2oBFT3oc\nUYarxO2c+uHF26J2lQRCtY8bwIidgDH7FmxyXa0pSijvKrFsjKas0bu775uazx8+mZaxxV2N1Mj4\nuCmJuqTwGK0vPxzQ04KwWKzdXrPistdY9nJp8kRGKYo7wCzVIFOsKyGqxOk3Dpvgd1LBt67l75Qv\nR1DM9pcknzro7wLWNJVezk9XGRPk3NjpsNzHH9f8nS1uZVwcdMW1iF0liSRqSLjHg3pZlJ1bgBUu\nFrDF6iMvxf16fjFlT+she70VrwNtCsIGZSlFme14iPShS9eZScikLHufOO7NEil/PS8fhpKw/Y7B\no4HL33Y+1KXcSU+dFbzYVW8DK98Mfl6Ws/4AAHgr/Xnn/db7c/fxpZczaIT3ftv4Q5zLl8ksFrwj\nEb1CRB8S0SIi+oEKwYLQM8gSIfBdjyfupKOCXbgMV0lDnXdyKQAAJVGTEOhytXZt5W+yhEDdfyZw\n/5dcrEJJxT00Hzng6uNeM6dwlfF+hSvlbPvUe38p92fy15y3OyjcTa0hZoDb+GF554fh47Zf49IX\ngPphzsdmObo45j8wM04B7jvN+5gL/+a+b/hOAIxIDmfimdmqu6ukH8CPhBB7AzgUwHeISCJIWR29\nNfl16TDCIX1rDCTcphIXHoQayqCzL+08scC+zbrc0waPOGSLsiavKffH/yz3sSAmde37wC17Gmlv\n7z4O2LjI/RqyTH3W/xg7t+/rc4BZP2vmAIv+IXdNN4vYof5bO7JTmh3uzdIXgRmn5aNt/BRruZnt\norC4LdPJXdnnnBDKlWCPU9z3ZV0lboOTyvJ0FxLnupMyiwWvA7DO/NxGRIsBjAdQpgkRHsIaqiab\nAyFyJBQ3JVGTMPp8V18ag3Mr1cgEcmcH6DIAbL/Zqpy86sOScvamlh/mt79+E9C2znkF7FItv4k+\nU81T9UB/wNwP2Q5793HG/8+XkVLVgS3tDjmjszw6FehtN/7qh8E3v03ZyiUMi9smQ+3g8q+pArM9\n1xY0ZduaoKXw2dySRQL0t7hzENFEGCu+z45CmFIRIoM30p/HlvMeD1lxR/wKljAGJwEj21i+WLeo\nCQel4GOp92U8HiCWlLMjhUXpdZgZ7hz9klEl9ynhvgXtsEf9yKP84nrq6u5xLyerBLPtLae3I1Lc\nYayCE5NlWjZEACVQm3CLKimxTZb5FtTQJplTPAKkFTcRDQHwOIArhBCtDvsvI6ImImpqbo4otaUT\n3a0Y3rESRyYXIbmrQ4Y3HyLLfSATFpZIoc5sjM6TTmQmfnh3xlqvsES3RR7WvGf8f+eP/uWHRUkP\nXJ/6sd9bL8XtQE5xO17brd4lXTHj9g8kC3pCeJuoVMUNAJS0WdwWSu3DNSWsn3lOfoHr7TqWehwY\nLVKKm4hqYCjtB4UQjsvGCCGmCyGmCCGmNDY2himjNx35h0S92zJMHhSF9IQ2Q1DOVZK1IgrjY82G\n+Pf/lCjHu9GOGuqSKB9wV5YqV3zPUkr8s1+HXfFa4fdal/UVrex6XO5jd2/2YeoRKiirDNfaJi/V\nDpE7L0wqWXEnkjkjxyAEV4nlvOUn3iN7Uu5Tf7/G+bjJSHF3D4DFQohboxcpIJbKlwrBs1Hkp/rg\nr47XjoRE/vVva6fENO+urUCfzQ/sI2PSa+q9fZGHnFxxKO4IXCVO6xq60biH8d8yEae7x+OeZOPB\nczL4hAPOtuUgUT0TEgBWhzhlHTB+Q1rRhByLkWNusApS2jUtMf3JsS6hhkXnWNyQblk9FSCj6Y4A\n8HUAxxHRXPPPJ7ZHIZbK90yjmuXzhaPkRat6tFvjlCUbhJOvTEYWSmLwto/wpcRb+HSLRcm4deq/\nng3cf0bhNh8ryjMccMJBztu9FLcQwIs/A67f3rPcwAyRSPpULIz37iAr1x/5QyNbn8Xi7umV8HEX\nzeJUvQ5mAF77TbjXe2kacP1ooL/MtSivXut/jMjgnB6XyCF7H5CVx9JvG+ol0vwahVlOj2EWqYlv\nyxZCvCGEICHEfkKIyebfv1QIJ0XQ1z9bCNSyZlusrrWzuynQJc8CdxxkDBj9+1rgxh0dDpLxcSeR\naPkUf6i9Ay2yCxlk/c95Ib2P91JeRMBODhnq/PzNb/4un9hHhm/7TPIAgIsel79eFr97H8T9kkga\n2fqSdblNvb0S98SuwGWJbGq8QrI54vsCvNk4USfhNvKaP2Dvpx2SY2zPX5X7OGRQnceBFnb5Yu5j\npl82GVr4VP7MyaCvnLYO016UUlXiek99F9j0MdC9DXj7DqDPYaLG7idKyJJXkCWv5+cnr5/V6ZRI\nKYilKsMYibD/4eODX/fek4Gube77y3RHDO3bCHRshqdS/vCfwNyH8t9lFXJUrpLnrwb+dlE01zbJ\nZ7PU5S3DVpeyxtzqfHBcXY2ke7DBMn6ns8WtPWUOuBStXL3FMjU52wlLebIeIrG4q8Ut0xlEcXds\nyn92+v1W5eE3881xJZgyO6JlgHfjKJeVy2XxU3Beq9KX0jYs51yLe4GbdvGW4envA//4tjqf9afv\nAOvmu+9/50/A4qeBbavDK/PrhQm/NrbZXEhB3x5W298ay8R+n0sI8yPZcR2LUTO+fzXQXRRgp4TK\nV9xlvqIW5RuYaJkWP2pXoPkj4JeNwEKHYJplr0iX48i2VbmPH6y2Wo4+v2m9teMWHyusjdBcPcSV\nU8vwe7Z+Bix9CVjwGLDhw3wj7tiYO2TtXpeWfn1AQvlafv+GD21KIb9POKVtLak8uFj5ZlnpEF6f\nvVbnufdk4K6jgK0rva/xqXcyqE8vlVgBKIttLKS5rUyf9j0nlHe+HftDs5QHtuxbpqVfn9f/DDDj\n1OBlhUAM4QMhE/jpalPc9gRPBRaoANabOYkXP22Z/ms2lCf+K2DZ7qzabPoJe9okGp7lNzhYehlK\nWuZS+jwEhjgMMnpmFLRc79a9ivdPaymQf2SPxMCTF04zQ60yWD/faWZvO+IK4+F26OUllufDQ191\n37f8VdmC3HeNcBozAfrTmXyH3fapsQSdGz6GQ8Mwn4RKVuqGAl++K7cWa87iLpi9a2PrKsOtoGJ2\nZufmwu+lvP2U6h70Sj0RIfpb3DOvNyw6N4I+XW0+3SMW/Ry442DrBQuvnZ2kEiipfnBGohXiulHA\njRMM/7ksjoo75bm/AKcwPK9O3y0xEcRyT/onftH/eMlrSfPm7UYKWstDiWSn0zstJ2Zn7fvF24Iq\ni8O/H+x4AB0dlrEU34FZS9duWQN8+FTB7iH1EknQrFiSZLVuMt1TrjN8AfxuP+CR/whWRhDWzTWi\nWgDjDcRKlBY3AHythIH0kNFfcc+6GXjc43U78LTnKwtCvvbZ+DSw6SNg3iPGq7awKe6s2yFixX1w\nYglIdjmn5iWWL8W/P11gofrUj1cSKifuPs57/5o5wMo3cl/rtisz6VcQV4mdLSVMSd5uV+BK24w4\nexvLOA1KBWiH01qAPX0iar/5cqHbDkDd45ZBR783TevD956TiiZz1dUEVNzr85blRbNsqVPd+uDy\nV4y5B1n+7yhjMDcs3rjN+AuDIIrb601HEforbj+CrF0HAA3bFa1wDsB4DbzzMBRZ3E6K2+9hUUJM\n8hja6n9Qllm3eMqStlrRvpaZU+hfGYOTdx+Xe6UGgsTHuuAn/+sO9zLLoxeXVqZ9oKqcAXAhgFvz\nkztu7LtQ7rzxBwJTC/PH1696VV6mR6caC+gCQKuDuyqoa8DxeBdXibVN3mvxAa+fD/z968HK9SNr\ndVux5JmXJkh9aJDIrvIVdymJYrwafZHFbd6kILPwEgGtGQC/qLlf/mBrnGr2tyx9KZcUKo0ArhKn\nRhhijHGDbHysG34K6kPJdK5BsNfJGxIThu1+93f+zxisFRmgNb+iecPBLvnAgzLvEeN/11agbX3w\n84PeYyfFZp812rXNeFgssTxwmhcHl61cFvw9+DlBFLc9x89Hzwcvr0wqX3HPMPL4diWH+hxowVMZ\nWDrg+3/JW6Sr3nA+3IkdfCI5soTyyiWATUuBB8/NJavvqrdY/EF8ofmNIchlUFfnkStFhjjya9gt\n7pWz/M+xuvOWvwo8/1PguZ8WPTi/frjH0lhBWGiO+9y6N3DLHu7H2XzbJTN4lMNGm8W92VzoI+wZ\nmhEzf8zZwRJO2dvH0n+HK5CMCMpLDJOe9tzHpz73a/nzvJTBP75d+N0xvtPHij1nupwcZ9/pf4wf\nQgDzC1cP6UpZcpA4xmlbCDo4GZRyr+V0rywWbCQUuUosn9s3whHr4Gc2JLB1TdFM1xENZT7I7PjN\nWpRKVCaB03wA++Bk1hJdX7w6vM4smRiwjuxv1F1bjSgahVS24v5Lfv27ZG2ADhHEiivFnyWThQ4A\nxu4X/Np2RAaYX/hq2G9OgNlw8l3AMJ9VTpx+X9u68uUKiziSMXn5uG/2WAU8d75Zpytez70RZiEN\n/KMlMbxwUeFea1bNbP34GQnlcMQVwY5fJZFmwWRw0HEY+z1c9KQRRaMQvRT3lhXAC/+bn1zwjoNF\n2rImv/Dq2vz6kjVBRsmD+MWXWJbcylkY8qd7EkYWvta1BRN50LIW1N2CDlEHsffZ/ueHPb09bF69\n0chqN224ce9bSrS2AywSXFwnAW+4132NKvOi28LRYZEqHKtobu9BkauklAyPsjjNN/BihsdSaJ+8\nBMy+K/d1cH3AvNxueeyta8JGjF4TcH5v+oZnTwd+sqwgCQwA4O8X5wejphXGEwdS3EEs7rfvyH/O\npIFkiFVWSiJ3O/+0xQPftjd2BQAC+l0zz1vQKdnRvl8tHlh6d7rxBwC3SabedOKgb8ofa6+TIFb/\nsPHqFHe7ZZD6/i+F43qTZGNrN8ZbBycXPWlEsgTlx8v8jwGAgy8D/n1N8Os78cC5BV8DRz653cM7\nDjRCSYM+ZEpAT3Mr3QM86ZDrwxpBYLO8amsDVH6pA15BQw9lOPQ75Z3v8VsGyyhundgjnunDfogg\n7WXIGO+3mKCKe9LR7vvmPVz43T4+48aPlweTwQFj9qSpuGfdWhiiGgRZ15GblRsCwRW3hyx3HlGe\nMLIiKCmlFJY8473fZn3VBrG4S/UzZl0sYSwjlcUps2AQNn3kuqtGdmGJScGXfIuEKK3/ugBRRzYy\nQRR3ssbbMAg64WmHA9z3lVpfDduVdt75D+Y+drdtyc9tmDNDTaa8fb8S7PhPXpI6LHDIqtc9VOR6\n1Fdx2/lkpufuuiAW99j9SrN0fzUu/BHz3jIVdxgcEXz6dSRE1OjX7Xg68LmTSz4/uTnA2oKrZwML\nHi25rCIO9nDxeGVGjAJLLvuznj+scF/BbN4gBHj4HPiNYJd+4Nz8A6VlDXDDOGNmr40hg0KM9Gkv\nIaa+BCpIcXs/PetqA1jcRMBRPyxNjrkP+x8ThBFlTgkPgzgiN5yYcLD/MSWwcdfz1Pry59wX3rVs\n0RwFvPOn8MqRIczxnRwB2t7EEtwQ2ba96EkjdNIhZcOQBgWJsEKmchS3jzVWXxfQB1aqz2zjotLO\nc+PoK8O9nsm7NS7LkjkRY0L4AoaNMwaddzw01MvWpspr5iL2hQI0IZKImKjrVgAta41oNRfqg0aV\naEDlKG5rdIcDg4O4SoDSY06l03ZKUhPyhAyTnvrR8gcHWYZMBSHPlqxJladwKLT4zwoninC/QQHS\ny5aCyADTv+h5CEUZfx4RMqu830tEG4konsSzkuwwImgsZkQ3y55ZLiaSqQADLjGunedMuIpSepDW\nShTWZSn5wZnyuGFswcIejugUEiuJTIu+D4BHNLseBO6cUc1gUxDDKUM6iOLWzuIOV3FPCPpQB4Aa\nydmvQdBg1mTriSWG7TFaIbPK++sAtiiQpeK4t9/2PDslQL6UiBk9PED4myXnixaE7CpJpkoYz9h+\nz1BlABDtzEJJhrUEWKTDTtiWaSoaN6ESPNJV9KWjT4wWmo+biC4joiYiampubvY/IWyGeYy+R8RW\nMaRww+jPlXahCx7yPyYge01o9D8oy+QIVyophdwScSHREKAuslz4SLgyAKVb3DsfGZ4MfkmpvKgf\nHp4cADBu/+DnJMtMExwW33LPGFmSay4goZUghJguhJgihJjS2FhCRymH024OPrGhTJ5rOBvnfmta\n4cZS/aLDdihbniKCuEoGjQCuVRN/KsVh3wWuCTHRVSkDwI5pTMuk1PZRzoLOdhrLeJMYOhbY68zw\nZDnv3uDnfK2EXNtViF65SkphWoizGANw6r47ADvaFnUttWNGMfEk6AITYUW3XPoicM+J5V2DKNxF\nZkdqECsPlN4+ypj1WcQBZaZ5tSZdK5fh44OfE2ZdVDCVEw7ohG1NvsBMawG+WGLiGqfX3u0dVj2X\nwbq6zn4XlHYNO6WsDFRu/PTh3wN2tEyiOei/yrveCdeVdz4ADIrAci6VUh/Qpbh63Cg3WiasfD2H\nfbe08zIu/mMdJrIpRCYc8GEAbwPYg4jWEJHHyr1lErRhT/XJZyLDMT8p7bxsOGHKjFi4Zl3pr9cp\nS2jiGbcZWd5O+mVp18qSLiHEr5TBp+3NnDH1I4ATflG47/QyIxiO+EF55wMIO7SwLEqddh/m20e5\nkS07HeZ/jB/nPwCcfENp547YyXn75fL5twEAnzMDC8pR+KN2Kf3cMpGJKrlQCDFOCFEjhJgghLgn\nMmmC+LxC6dQofaQ8q7izERDldIhsIqFj/9fopJP/Axg0svCY7xbnWMhxzE+BKxYAl7yQ3+a4ErkP\nx/2/4m1fuc/7nFNuNP6P3Tf8cQYi4OfbyrvG5JDWeAyDsftGX4Z1foJT5EO58xdOl1h/0wnrW8Ne\nXyq9/KFjgLP+WLy9tgE4MkAaizNuN6/ns9CIF995r3hbCevNloJerpI9TpdPeD9mn/DKnfov4GuP\nF2770u+9z8lOmc8lkS+jKokMt80xluWh7L680bvlowu+9SbwwyXAbicYFsOx1xiWyE6H5EMSgyxu\nnMUpF4RbTPW33gCuXpt/dY4qK1o5D9ZLXyz/zaUczrXYON97v7xr7Xq8+76Gxnx7HW4Zd8kOUFuy\n+pUd0jdm7+DnfOl3wGWvGfVx1afllQ94hFUGyZs+DjjnbsP6LxWn3C1DxhRviwC9FHeqFrj0BeAi\nU4nu+xXgJyuMcLlr1gE/+tj4/K03gqd49GLiEcBES8jVGbcDB14M/I9HXpKs5fKFi4z/Ycfo7mmx\nSk683vg/9RngZ1uBsfsYDe+ix4Er5hee9/kvG53XK6ucF/ucZ/zP+bttnWHKpcBVqw3rsW5IfsHj\nPU4rrTwZjnXIM3HstYXfG/cEDvl2/oG+91mGv70cRfWN54zOLYtdOe97nhGtc/lsYLsyFwn+2qPA\nUT8q3JZ9Czv028CEKcZnqysjG74XdloF63wFmfueqjcGIvc9L5yQwtzDw3ZvP+8TRnr1WuMNLhvQ\nsN9XgCFljh/810yg1mJkXfJcedeTRM+okt1OKIwW2fN043/t4PznsKmpB47/udEQs5Mvhk8Avttk\nKOn1C4zyZ98FfPx8/hXr9FuBk24I302QSBirtrz35/zrPpG/Iho6FvifMrITnH2nYcGveA1Y/Q4w\nyqZwEimg3rIY8ahdjIer3bUTJkdfCbxis5z3ORd4xeInTdUBp5oKZdvqcGaw7ny4d9rd3U8Cllrc\nU1blnB0ErBkUzmSeRBI4/mdGO8yWWTu4sJ/8ZIVR7tIXgK/+BRg1CXjjdiPf+oFTge0k1suUodGy\nqvxX7gf+9rXCeoiacfsDP11ptLk3f5df43XcfsbD8w8HACf/qnjFnLohRZcqmwlTgDN/Bzx2ifHd\nzQcfMiQiSOk5ZcoU0dTU5H9gJZLuN1bi2efc6HMcpPuMnMtxhLMJYSwaPGwHYNNSY1mqDQuBw78P\nnHS997lN9xqTkSaGOHGkpx240Qwfy3ba5o+BP5pZEI+6EjjewUcfBnMfBiYdBTx0vuHKazJdINNa\ngLb1wC17GG8/u50APPhVYOm/8/vDJt0HvPxL4M3bjbfQMAcuZVn2MvDXLxufp7UA3S3Ar10U1qRj\njLeFIPMKwuKlaUZ9feEi46EVSVpaFLbNMu45Ec0RQkyROpYVNyPFrFuAmb8AjrkKOPbqeGRY+Diw\n8xHGW4WVljXGG5CKXCBCANeZGe3cOulD5xtJ//eIMMWPEPElR9q6yljV/PRbgYPMILNpFhfI+Q8Y\nD+6me4GTb1Q+OS4WHp1qPMQveb7kS7DiZsKnpx2YeZ3hTorilbOSyCqpmCZ/aUFvp+EGyj48Fj8D\njNixtGnsDIBgiltPHzejH3VDgNNuilsKPTj1psKJRgMRu4tmrzPikWOAwoqbYYJyyGVxS8AMcAaA\n84lhGKa6YMXNMAxTYbDiZhiGqTBYcTMMw1QYrLgZhmEqDFbcDMMwFQYrboZhmAqDFTfDMEyFEcmU\ndyJqBrCqxNNHA9gUojiqYLnVU6mys9zqqQTZdxZCSOWZjURxlwMRNcnO19cJlls9lSo7y62eSpbd\nCXaVMAzDVBisuBmGYSoMHRX39LgFKBGWWz2VKjvLrZ5Klr0I7XzcDMMwjDc6WtwMwzCMB9oobiI6\nhYg+IqJPiOiquOWxQ0QriWgBEc0loiZz2ygiepGIlpr/R1qOv9r8LR8R0cmKZb2XiDYS0ULLtsCy\nEtGB5m/+hIh+TxTtWlkuck8jorVmvc8lotMs+3SRe0cieoWIPiSiRUT0A3O71nXuIXcl1Hk9Eb1L\nRPNM2a8zt2td56EhhIj9D0ASwDIAuwCoBTAPwN5xy2WTcSWA0bZtvwVwlfn5KgC/MT/vbf6GOgCT\nzN+WVCjr0QAOALCwHFkBvAvgUAAE4DkAp8Yg9zQAVzocq5Pc4wAcYH4eCuBjUz6t69xD7kqocwIw\nxPxcA2C2Wb7WdR7Wny4W98EAPhFCLBdC9AJ4BMBZMcskw1kA7jc/3w/gbMv2R4QQPUKIFQA+gfEb\nlSCEeB3AFtvmQLIS0TgAw4QQ7wijdf/Fco5Kud3QSe51Qoj3zc9tABYDGA/N69xDbje0kNuUVwgh\n2s2vNeafgOZ1Hha6KO7xAFZbvq+BdwOKAwHgJSKaQ0TZtavGCCHWmZ/XAxhjftbx9wSVdbz52b49\nDr5HRPNNV0r21VdLuYloIoAvwLAAK6bObXIDFVDnRJQkorkANgJ4UQhRUXVeDroo7krgSCHEZACn\nAvgOER1t3Wk+rSsiRKeSZAVwJwwX2mQA6wDcEq847hDREACPA7hCCNFq3adznTvIXRF1LoRIm31y\nAgzreR/bfm3rvFx0UdxrAexo+T7B3KYNQoi15v+NAJ6E4frYYL5qwfy/0Txcx98TVNa15mf7dqUI\nITaYHTQD4M/Iu5y0kpuIamAovweFEE+Ym7Wvcye5K6XOswghtgF4BcApqIA6DwNdFPd7AHYnoklE\nVAvgAgD/jFmmHETUQERDs58BnARgIQwZLzYPuxjAU+bnfwK4gIjqiGgSgN1hDIDESSBZzdfNViI6\n1Bxl/0/LOcrIdkKTL8Ood0Ajuc1y7gGwWAhxq2WX1nXuJneF1HkjEY0wPw8CcCKAJdC8zkMj7tHR\n7B+A02CMai8DcG3c8thk2wXGiPQ8AIuy8gHYDsBMAEsBvARglOWca83f8hEUj1IDeBjGK24fDJ/d\npaXICmAKjE67DMAdMCdsKZb7rwAWAJgPo/ON01DuI2G8ks8HMNf8O033OveQuxLqfD8AH5gyLgTw\nM3O71nUe1h/PnGQYhqkwdHGVMAzDMJKw4mYYhqkwWHEzDMNUGKy4GYZhKgxW3AzDMBUGK26GYZgK\ngxU3wzBMhcGKm2EYpsL4//VxMHjQKsH8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ca38358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(crps_train_list)\n",
    "plt.plot(crps_predict_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erm, well something is not right here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
