{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Fully-connected-linear-network\" data-toc-modified-id=\"Fully-connected-linear-network-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Fully connected linear network</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Get-temperature-data\" data-toc-modified-id=\"Get-temperature-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Get temperature data</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Build-fully-connected-model\" data-toc-modified-id=\"Build-fully-connected-model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Build fully connected model</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Predict-for-one-day\" data-toc-modified-id=\"Predict-for-one-day-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Predict for one day</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Post-processing-with-rolling-window-for-2016\" data-toc-modified-id=\"Post-processing-with-rolling-window-for-2016-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Post processing with rolling window for 2016</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Train-2015,-predict-2016\" data-toc-modified-id=\"Train-2015,-predict-2016-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Train 2015, predict 2016</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Neural-network-with-one-hidden-layer\" data-toc-modified-id=\"Neural-network-with-one-hidden-layer-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Neural network with one hidden layer</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Build-network\" data-toc-modified-id=\"Build-network-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Build network</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Train-2015,-predict-2016\" data-toc-modified-id=\"Train-2015,-predict-2016-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train 2015, predict 2016</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Hidden-model-with-station-embeddings\" data-toc-modified-id=\"Hidden-model-with-station-embeddings-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Hidden model with station embeddings</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Get-the-station-data-and-prepare-as-input-for-embedding-layer\" data-toc-modified-id=\"Get-the-station-data-and-prepare-as-input-for-embedding-layer-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Get the station data and prepare as input for embedding layer</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Build-embedding-model\" data-toc-modified-id=\"Build-embedding-model-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Build embedding model</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Train-2015,-predict-2016\" data-toc-modified-id=\"Train-2015,-predict-2016-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Train 2015, predict 2016</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Embedding-size-hyper-parameter-tuning\" data-toc-modified-id=\"Embedding-size-hyper-parameter-tuning-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Embedding size hyper-parameter tuning</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Adding-additional-variables-to-hidden-layer-model\" data-toc-modified-id=\"Adding-additional-variables-to-hidden-layer-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Adding additional variables to hidden layer model</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Get-additional-variables\" data-toc-modified-id=\"Get-additional-variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Get additional variables</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Build-model-and-predict-for-2016\" data-toc-modified-id=\"Build-model-and-predict-for-2016-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Build model and predict for 2016</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Hidden-nodes-hyper-parameter-tuning\" data-toc-modified-id=\"Hidden-nodes-hyper-parameter-tuning-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Hidden nodes hyper-parameter tuning</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Additional-variables-with-the-embedding-model\" data-toc-modified-id=\"Additional-variables-with-the-embedding-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Additional variables with the embedding model</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/fc_network.ipynb#Build-model-and-predict-for-2016\" data-toc-modified-id=\"Build-model-and-predict-for-2016-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Build model and predict for 2016</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected neural networks\n",
    "\n",
    "In this notebook we will expand the simple EMOS linear network to fully connected non-linear neural nets. Furthermore, we will also use auxiliary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from importlib import reload\n",
    "import emos_network_theano; reload(emos_network_theano)\n",
    "from  emos_network_theano import EMOS_Network\n",
    "from crps_loss import crps_cost_function\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "# import the keras modules\n",
    "# Note that the cost function only works with the theano backend\n",
    "import keras\n",
    "from keras.layers import Input, Dense, merge, Embedding, Flatten, Dropout\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "DATA_DIR = '/Volumes/STICK/data/ppnn_data/'  # Mac\n",
    "# DATA_DIR = '/project/meteo/w2w/C7/ppnn_data/'   # LMU\n",
    "fn = 'data_interpolated_00UTC.nc'   # Temperature observation and forecast data\n",
    "window_size = 25   # Days in rolling window\n",
    "fclt = 48   # Forecast lead time in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected linear network\n",
    "\n",
    "As a first step, we can build a linear model which also connects the means and standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get temperature data\n",
    "\n",
    "This follows the steps in the EMOS Network data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "tobs_full, tfc_full, dates = load_nc_data(DATA_DIR + fn)\n",
    "tobs_full.shape, tfc_full.shape, dates.shape\n",
    "# Pick an example day\n",
    "date_idx = return_date_idx(dates, 2011, 2, 14)   # year, month, day\n",
    "# Now get the training and test data for this day\n",
    "tfc_mean_train, tfc_std_train, tobs_train, tfc_mean_test, tfc_std_test, tobs_test = \\\n",
    "        get_train_test_data(tobs_full, tfc_full, date_idx, window_size, fclt, \n",
    "                            subtract_std_mean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build fully connected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_fc_model():\n",
    "    inp = Input(shape=(2,))\n",
    "    x = Dense(2, activation='linear')(inp)\n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model()\n",
    "fc_model.compile(optimizer=SGD(0.1), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 6 parameters instead of 4 with the standard EMOS Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "early_stopping_delta = 1e-4   # How much the CRPS must improve before stopping\n",
    "steps_max = 1000   # How many steps to fit at max\n",
    "batch_size = tfc_mean_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12619, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We also need to concatenate the input arrays\n",
    "in_train = np.column_stack([tfc_mean_train, tfc_std_train])\n",
    "in_test = np.column_stack([tfc_mean_test, tfc_std_test])\n",
    "in_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12baa19b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(in_train, tobs_train, epochs=steps_max, batch_size=batch_size,\n",
    "          validation_data=[in_test, tobs_test], verbose=0,\n",
    "          callbacks=[EarlyStopping(monitor='loss', min_delta=early_stopping_delta,\n",
    "                                  patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.224784107227332, 0.75179883171599682)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get train and test CRPS\n",
    "(fc_model.evaluate(in_train, tobs_train, batch_size, verbose=0), \n",
    " fc_model.evaluate(in_test, tobs_test, batch_size, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular day we get a score that is slightly better than the standard EMOS network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing with rolling window for 2016\n",
    "\n",
    "As with the EMOS models let's do a rolling window global post-processing for 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_idx_start = return_date_idx(dates, 2016, 1, 1)\n",
    "date_idx_stop = return_date_idx(dates, 2016, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model()\n",
    "fc_model.compile(optimizer=SGD(0.1), loss=crps_cost_function, \n",
    "                    metrics=[crps_cost_function])\n",
    "# Note that we have to define a metric in the corrent loop implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "Time: 196.83 s\n"
     ]
    }
   ],
   "source": [
    "# Use the loop function in utils\n",
    "train_crps_list, valid_crps_list = loop_over_days(\n",
    "    fc_model,\n",
    "    tobs_full, \n",
    "    tfc_full, \n",
    "    date_idx_start, date_idx_stop, \n",
    "    window_size=window_size,\n",
    "    fclt=fclt,     \n",
    "    epochs_max=steps_max, \n",
    "    early_stopping_delta=early_stopping_delta, \n",
    "    lr=0.1,   \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.97781397659532787, 1.0036478569781389)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_crps_list), np.mean(valid_crps_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get a slightly better training score and a slightly worse test score. This is a sign of overfitting. But the differences are small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 2015, predict 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfc_mean_train, tfc_std_train, tobs_train, tfc_mean_test, tfc_std_test, tobs_test = \\\n",
    "        get_train_test_data(tobs_full, tfc_full, date_idx_start, window_size=365, fclt=0, \n",
    "                            subtract_std_mean=False, test_plus=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = build_fc_model()\n",
    "fc_model.compile(optimizer=SGD(0.1), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180849, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_train = np.column_stack([tfc_mean_train, tfc_std_train])\n",
    "in_test = np.column_stack([tfc_mean_test, tfc_std_test])\n",
    "in_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 181718 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 2.7792 - val_loss: 1.6748\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.3894 - val_loss: 1.2322\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.1722 - val_loss: 1.0815\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0971 - val_loss: 1.0317\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0762 - val_loss: 1.0172\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0709 - val_loss: 1.0140\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0696 - val_loss: 1.0122\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0692 - val_loss: 1.0124\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0692 - val_loss: 1.0115\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0691 - val_loss: 1.0111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11bee8828>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.fit(in_train, tobs_train, epochs=10, batch_size=1024,\n",
    "             validation_data=[in_test, tobs_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar to the standard EMOS Network. This indicates that there is not much additional information in the two extra connections we added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network with one hidden layer\n",
    "\n",
    "Now we will build the first neural network with a hidden layer and a non-linear activation function. We will restrict ourselves to testing the 2015 training, 2016 prediction case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "hidden_nodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_hidden_model(hidden_nodes, feature_size=2):\n",
    "    inp = Input(shape=(feature_size,))\n",
    "    x = Dense(hidden_nodes, activation='relu')(inp)\n",
    "    x = Dense(2, activation='linear')(x)\n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 52\n",
      "Trainable params: 52\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_model = build_hidden_model(hidden_nodes)\n",
    "hidden_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_model.compile(optimizer=Adam(0.01), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 2015, predict 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 181718 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0643 - val_loss: 1.0191\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0614 - val_loss: 1.0219\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0614 - val_loss: 1.0235\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0613 - val_loss: 1.0202\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0613 - val_loss: 1.0201\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0613 - val_loss: 1.0263\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0618 - val_loss: 1.0212ss: 1.\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0612 - val_loss: 1.0221\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0613 - val_loss: 1.0221\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0612 - val_loss: 1.0252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11bee8b00>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the same data from above!\n",
    "hidden_model.fit(in_train, tobs_train, epochs=10, batch_size=4096,\n",
    "                 validation_data=[in_test, tobs_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loss is consistently smaller than the validation loss. This indicates overfitting. We could use Dropout for regularization. But since this model is just an intermediate step anyway, we will ignore that for now. The differences are small anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden model with station embeddings\n",
    "\n",
    "Next we will add a station embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get the station data and prepare as input for embedding layer\n",
    "For this we will use a more general data loading function which will also be able to handle the auxiliary data. Eventually I could maybe write one general function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target, features, dates = prepare_data(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3653, 537)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features_train, target_train, features_test, target_test, id_array_train, id_array_test = \\\n",
    "    scale_and_split(target, features, date_idx_start, 365, return_id_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((180849, 2), (181718, 2), (180849,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, features_test.shape, id_array_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Build embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_emb_model(hidden_nodes, emb_size, max_id, feature_size=2):\n",
    "    features_in = Input(shape=(feature_size,))\n",
    "    id_in = Input(shape=(1,))\n",
    "    emb = Embedding(max_id + 1, emb_size)(id_in)\n",
    "    emb = Flatten()(emb)\n",
    "    x = Concatenate()([features_in, emb])\n",
    "    x = Dense(hidden_nodes, activation='relu')(x)\n",
    "    x = Dense(2, activation='linear')(x)\n",
    "    model = Model(inputs=[features_in, id_in], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 536)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_size = 5\n",
    "max_id = int(np.max([id_array_test.max(), id_array_train.max()]))\n",
    "hidden_nodes, max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_19 (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 1, 5)          2685        input_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_18 (InputLayer)            (None, 2)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 5)             0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 7)             0           input_18[0][0]                   \n",
      "                                                                   flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 10)            80          concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 2)             22          dense_17[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 2,787\n",
      "Trainable params: 2,787\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model = build_emb_model(hidden_nodes, emb_size, max_id)\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emb_model.compile(optimizer=Adam(0.01), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train 2015, predict 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 181718 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 3.1504 - val_loss: 0.9579\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9834 - val_loss: 0.9228\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9741 - val_loss: 0.9163\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9723 - val_loss: 0.9144\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9719 - val_loss: 0.9147\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9714 - val_loss: 0.9145\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9712 - val_loss: 0.9112\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9702 - val_loss: 0.9151\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9707 - val_loss: 0.9117\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9702 - val_loss: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e408198>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit([features_train, id_array_train], target_train, epochs=10, \n",
    "              batch_size=1024, \n",
    "              validation_data=[[features_test, id_array_test], target_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding size hyper-parameter tuning\n",
    "\n",
    "Since embeddings appear to work very well, we will test the impact of the embedding size before building more complex models. Of course, a larger embedding size might be useful when adding more variables, but this should give us some feeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_run_emb_model(emb_size):\n",
    "    emb_model = build_emb_model(hidden_nodes, emb_size, max_id)\n",
    "    emb_model.compile(optimizer=Adam(0.01), loss=crps_cost_function)\n",
    "    emb_model.fit([features_train, id_array_train], target_train, epochs=20, \n",
    "                  batch_size=1024, verbose=0,\n",
    "                  validation_data=[[features_test, id_array_test], target_test])\n",
    "    print(emb_model.evaluate([features_train, id_array_train], target_train, verbose=0),\n",
    "          emb_model.evaluate([features_test, id_array_test], target_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.967700981302 0.928655344943\n",
      "2\n",
      "0.960589448223 0.917231013011\n",
      "3\n",
      "0.96050738703 0.920315323502\n",
      "5\n",
      "0.958451787728 0.923359214098\n",
      "10\n",
      "0.960904902009 0.925523586535\n",
      "20\n",
      "0.959896959686 0.919102417839\n"
     ]
    }
   ],
   "source": [
    "for emb_size in [1, 2, 3, 5, 10, 20]:\n",
    "    print(emb_size)\n",
    "    build_and_run_emb_model(emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is some variability. In our first experiment above with an embedding size of 5 we got a better score than here. For this very simple network an embedding size of two seems sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional variables to hidden layer model\n",
    "\n",
    "Now we can try adding additional variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get additional variables\n",
    "\n",
    "Using the function defined in utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The prepare_data function takes an ordered dict as an input\n",
    "aux_dict = OrderedDict()\n",
    "aux_dict['data_aux_geo_interpolated.nc'] = ['orog', \n",
    "                                            'station_alt', \n",
    "                                            'station_lat', \n",
    "                                            'station_lon']\n",
    "aux_dict['data_aux_pl500_interpolated_00UTC.nc'] = ['u_pl500_fc',\n",
    "                                                    'v_pl500_fc',\n",
    "                                                    'gh_pl500_fc']\n",
    "aux_dict['data_aux_pl850_interpolated_00UTC.nc'] = ['u_pl850_fc',\n",
    "                                                    'v_pl850_fc',\n",
    "                                                    'q_pl850_fc']\n",
    "aux_dict['data_aux_surface_interpolated_00UTC.nc'] = ['cape_fc',\n",
    "                                                      'sp_fc',\n",
    "                                                      'tcc_fc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target, features, dates = prepare_data(DATA_DIR, aux_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3653, 537)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features_train, target_train, features_test, target_test, id_array_train, id_array_test = \\\n",
    "    scale_and_split(target, features, date_idx_start, 365, return_id_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180849, 24)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and predict for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_model = build_hidden_model(hidden_nodes, feature_size=features_train.shape[1])\n",
    "hidden_model.compile(optimizer=Adam(0.01), loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                250       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 272\n",
      "Trainable params: 272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 181718 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 3.0880 - val_loss: 1.7341\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.2352 - val_loss: 1.1541\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0377 - val_loss: 0.9793\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9775 - val_loss: 0.9483\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9706 - val_loss: 0.9398\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9677 - val_loss: 0.9378\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9673 - val_loss: 0.9415\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9667 - val_loss: 0.9410\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9662 - val_loss: 0.9494\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9656 - val_loss: 0.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11aebdfd0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_model.fit(features_train, target_train, epochs=10, batch_size=1024,\n",
    "                 validation_data=[features_test, target_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a comparison: Without extra variables we got a train/test CRPS of 1.06/1.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Hidden nodes hyper-parameter tuning\n",
    "\n",
    "Let's see what the impact of the number of hidden nodes is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_and_run_hidden_model(hidden_nodes):\n",
    "    hidden_model = build_hidden_model(hidden_nodes, feature_size=features_train.shape[1])\n",
    "    hidden_model.compile(optimizer=Adam(0.01), loss=crps_cost_function)\n",
    "    hidden_model.fit(features_train, target_train, epochs=20, \n",
    "                  batch_size=1024, verbose=0,\n",
    "                  validation_data=[features_test, target_test])\n",
    "    print(hidden_model.evaluate(features_train, target_train, verbose=0),\n",
    "          hidden_model.evaluate(features_test, target_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.974514032233 0.940623703924\n",
      "25\n",
      "0.945970456422 0.941868895928\n",
      "50\n",
      "0.94803293894 0.945383845405\n",
      "100\n",
      "0.915761278749 0.948940331101\n",
      "250\n",
      "0.89342511785 0.9350900614\n",
      "1000\n",
      "0.849479069772 0.956297336513\n"
     ]
    }
   ],
   "source": [
    "for hidden_nodes in [10, 25, 50, 100, 250, 1000]:\n",
    "    print(hidden_nodes)\n",
    "    build_and_run_hidden_model(hidden_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So with a larger network we get serious overfitting. Again, I would think that adding regularization with a larger network would maybe give the best results. Something to explore later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional variables with the embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and predict for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_nodes, emb_size, feature_size = 50, 5, features_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_54 (InputLayer)            (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)         (None, 1, 5)          2685        input_54[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_53 (InputLayer)            (None, 24)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 5)             0           embedding_18[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)     (None, 29)            0           input_53[0][0]                   \n",
      "                                                                   flatten_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_61 (Dense)                 (None, 50)            1500        concatenate_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_62 (Dense)                 (None, 2)             102         dense_61[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 4,287\n",
      "Trainable params: 4,287\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model = build_emb_model(hidden_nodes, emb_size, max_id, feature_size)\n",
    "emb_model.compile(optimizer=Adam(0.01), loss=crps_cost_function)\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 181718 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.8184 - val_loss: 0.9653\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9415 - val_loss: 0.9113\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.9057 - val_loss: 0.8758\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8804 - val_loss: 0.8722\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8692 - val_loss: 0.8627\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8636 - val_loss: 0.8644\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8600 - val_loss: 0.8746\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8555 - val_loss: 0.8627\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 0.8520 - val_loss: 0.8828\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 1s - loss: 0.8475 - val_loss: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131471ac8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.fit([features_train, id_array_train], target_train, epochs=10, \n",
    "              batch_size=1024, \n",
    "              validation_data=[[features_test, id_array_test], target_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
