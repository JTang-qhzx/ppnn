{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8888/notebooks/EMOS_network.ipynb#Prepare-the-data\" data-toc-modified-id=\"Prepare-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Prepare the data</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/EMOS_network.ipynb#Theano-Implementation\" data-toc-modified-id=\"Theano-Implementation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Theano Implementation</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/EMOS_network.ipynb#Train-for-a-single-day\" data-toc-modified-id=\"Train-for-a-single-day-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Train for a single day</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/EMOS_network.ipynb#Post-processing-for-all-of-2016-with-a-rolling-window\" data-toc-modified-id=\"Post-processing-for-all-of-2016-with-a-rolling-window-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Post processing for all of 2016 with a rolling window</a></span></li></ul></li><li><span><a href=\"http://localhost:8888/notebooks/EMOS_network.ipynb#Keras-implementation\" data-toc-modified-id=\"Keras-implementation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Keras implementation</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8888/notebooks/EMOS_network.ipynb#Predict-for-one-day\" data-toc-modified-id=\"Predict-for-one-day-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Predict for one day</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/EMOS_network.ipynb#Post-processing-for-2016\" data-toc-modified-id=\"Post-processing-for-2016-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Post-processing for 2016</a></span></li><li><span><a href=\"http://localhost:8888/notebooks/EMOS_network.ipynb#Train-2015,-predict-2016\" data-toc-modified-id=\"Train-2015,-predict-2016-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Train 2015, predict 2016</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMOS Network\n",
    "\n",
    "The goal of this notebook is to build and test a network implementation of EMOS, once in pure theano and then in keras. First we will try to replicate the results of the standard global EMOS. \n",
    "\n",
    "The reference period is always the mean CRPS for all dates and stations in 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Note that the cost function only works with the theano backend for keras\n",
    "from importlib import reload\n",
    "import emos_network_theano; reload(emos_network_theano)\n",
    "from  emos_network_theano import EMOS_Network\n",
    "from crps_loss import crps_cost_function\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "DATA_DIR = '/Volumes/STICK/data/ppnn_data/'  # Mac\n",
    "# DATA_DIR = '/project/meteo/w2w/C7/ppnn_data/'   # LMU\n",
    "results_dir = '../results/'   # Where to save post-processed predictions\n",
    "window_size = 25   # Days in rolling window\n",
    "fclt = 48   # Forecast lead time in hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "The interpolated raw data set contains the observations and forecasts from the 50 members for each station and each day. Using the `get_train_test_sets` function we will convert this raw dataset to a format suitable for the networks.\n",
    "\n",
    "Here we pick a forecast date and return as the training data all previous days within the window size previous to the start of the forecast. The test data is simply the data for the chosen forecast date. The 50 member ensemble is summarized by the mean and the standard deviation. Additionally, we remove all data where the observations are missing. Finally, the inputs are scaled. For this we simply divide each feature by its maximum in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chose a random date to illustrate the algorithm\n",
    "date_str = '2011-02-14'   # This is our standard date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 25 days\n",
      "test set contains 1 days\n"
     ]
    }
   ],
   "source": [
    "# Load training and test set\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, predict_date=date_str,\n",
    "                                          fclt=fclt, window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two sets are objects which contain all the data and some meta information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t2m_fc_mean', 't2m_fc_std']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12619, 2), (12619,), (12619,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.features.shape, train_set.targets.shape, train_set.date_strs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((503, 2), (503,), (503,))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.features.shape, test_set.targets.shape, test_set.date_strs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano Implementation\n",
    "\n",
    "To start with we build the model in pure theano. The model is defined in a separate script `EMOS_network_theano.py`. The network uses a custom CRPS loss function which is defined in `crps_loss.py`.\n",
    "\n",
    "The EMOS_Network class is build to work in a similar way to keras models. For the fitting we are using gradient descent. Since we are using the entire dataset for each update, it is not stochastic. An early stopping algorithm is built into the fitting function. It stops training if the average training CRPS of the last 5 steps is decreasing by less than a parameter delta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train for a single day\n",
    "\n",
    "To illustrate how the model work we will use the data for our example day above and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some model parameters\n",
    "lr = np.asarray(0.1, dtype='float32')   # The learning rate\n",
    "early_stopping_delta = 1e-4   # How much the CRPS must improve before stopping\n",
    "steps_max = 1000   # How many steps to fit at max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the theano model\n",
    "model_theano = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t2m_fc_mean', 't2m_fc_std']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the features into means and standard deviation\n",
    "train_set.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mean = train_set.features[:, 0]\n",
    "train_std = train_set.features[:, 1]\n",
    "test_mean = test_set.features[:, 0]\n",
    "test_std = test_set.features[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(1.1374654313399257), array(0.778464882363388))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for some steps\n",
    "model_theano.fit(train_mean, train_std, train_set.targets, steps_max, \n",
    "                 (test_mean, test_std, test_set.targets), lr=lr, \n",
    "                 early_stopping_delta=early_stopping_delta)\n",
    "# Output is the training CRPS and the test CRPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing for all of 2016 with a rolling window\n",
    "\n",
    "To compare the network model with the standard EMOS we will run it from 1 January 2016 to 31 December 2016. When looping over the days we are not resetting the model weights for each day. This drastically reduces the training time with identical results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get start and stop indices\n",
    "date_str_start = '2016-01-01'\n",
    "date_str_stop = '2017-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_theano = EMOS_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [05:45<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# This function loops over the days.\n",
    "train_crps_list, valid_crps_list, results_df = loop_over_days(\n",
    "    DATA_DIR,\n",
    "    model_theano,\n",
    "    date_str_start, date_str_stop, \n",
    "    window_size=window_size,\n",
    "    fclt=fclt,     \n",
    "    epochs_max=steps_max, \n",
    "    early_stopping_delta=early_stopping_delta, \n",
    "    lr=lr,\n",
    "    verbose=0,\n",
    "    model_type='EMOS_Network_theano')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that before restructuring the data preparation function, this was significantly slower. It might have to do with the creation of the meta data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0201273233365458"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what the mean prediction CRPS is\n",
    "np.mean(valid_crps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the results\n",
    "results_df.to_csv(results_dir + 'emos_network_rolling_window.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is then read by the evaluation script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras implementation\n",
    "\n",
    "Now let's build the same model in keras. This will provide a good starting point to expand the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the keras modules\n",
    "# Note that the cost function only works with the theano backend\n",
    "import keras\n",
    "from keras.layers import Input, Dense, merge, Embedding, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build the model with Keras' functional API\n",
    "# This is quite a bit easier and shorter than in theano \n",
    "def build_EMOS_Network_keras():\n",
    "    mean_in = Input(shape=(1,))\n",
    "    std_in = Input(shape=(1,))\n",
    "    mean_out = Dense(1, activation='linear')(mean_in)\n",
    "    std_out = Dense(1, activation='linear')(std_in)\n",
    "    x = keras.layers.concatenate([mean_out, std_out], axis=1)\n",
    "    return Model(inputs=[mean_in, std_in], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras = build_EMOS_Network_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             2           input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             2           input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 2)             0           dense_7[0][0]                    \n",
      "                                                                   dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model with SGD optimizer and our custom loss function\n",
    "opt = SGD(lr=0.1)  \n",
    "model_keras.compile(optimizer=opt, loss=crps_cost_function, \n",
    "                    metrics=[crps_cost_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for one day\n",
    "\n",
    "In keras the early stopping algorithm works slightly differently. It stops training once the training loss hasn't decreased by an amount delta in a certain number of steps (patience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This way we have the gradient descent on the whole training set just as in theano\n",
    "batch_size = train_mean.shape[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12051fe80>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.fit([train_mean, train_std], train_set.targets, epochs=steps_max, \n",
    "                batch_size=batch_size,\n",
    "                validation_data=[[test_mean, test_std], test_set.targets], \n",
    "                verbose=0,\n",
    "                callbacks=[EarlyStopping(monitor='loss', \n",
    "                                         min_delta=early_stopping_delta,\n",
    "                                         patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.1320928811822395, 1.1320928811822393],\n",
       " [0.77120698033628332, 0.77120698033628332])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get train and test CRPS\n",
    "(model_keras.evaluate([train_mean, train_std], train_set.targets, batch_size, verbose=0), \n",
    " model_keras.evaluate([test_mean, test_std], test_set.targets, batch_size, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get very similar results to the theano implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing for 2016\n",
    "\n",
    "Same as above with the theano model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras = build_EMOS_Network_keras()\n",
    "opt = SGD(lr=0.1)  \n",
    "model_keras.compile(optimizer=opt, loss=crps_cost_function, \n",
    "                    metrics=[crps_cost_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [08:14<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "date_str_start = '2016-01-01'\n",
    "date_str_stop = '2017-01-01'\n",
    "# This function loops over the days.\n",
    "train_crps_list, valid_crps_list, results_df = loop_over_days(\n",
    "    DATA_DIR,\n",
    "    model_keras,\n",
    "    date_str_start, date_str_stop, \n",
    "    window_size=window_size,\n",
    "    fclt=fclt,     \n",
    "    epochs_max=steps_max, \n",
    "    early_stopping_delta=early_stopping_delta, \n",
    "    lr=lr,\n",
    "    verbose=0,\n",
    "    model_type='EMOS_Network_keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keras implementation is slower than the pure theano version. This could be due to the overhead of calling model.fit many many times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99132742167771914, 1.0064540886440319)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_crps_list), np.mean(valid_crps_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are very similar to the theano implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 2015, predict 2016\n",
    "\n",
    "Finally, we will train one single model on all of the 2015 data, and then post-process all of 2016 with this one model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dates = ['2015-01-01', '2016-01-01']\n",
    "test_dates =  ['2016-01-01', '2017-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set contains 365 days\n",
      "test set contains 366 days\n"
     ]
    }
   ],
   "source": [
    "# Load data sets\n",
    "train_set, test_set = get_train_test_sets(DATA_DIR, train_dates, test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_keras = build_EMOS_Network_keras()\n",
    "opt = Adam(lr=0.1)  # Adam is a better SGD in a nutshell\n",
    "model_keras.compile(optimizer=opt, loss=crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_mean = train_set.features[:, 0]\n",
    "train_std = train_set.features[:, 1]\n",
    "test_mean = test_set.features[:, 0]\n",
    "test_std = test_set.features[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180849 samples, validate on 182218 samples\n",
      "Epoch 1/10\n",
      "180849/180849 [==============================] - 0s - loss: 3.0256 - val_loss: 1.9569\n",
      "Epoch 2/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.3893 - val_loss: 1.0758\n",
      "Epoch 3/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0758 - val_loss: 1.0133\n",
      "Epoch 4/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0693 - val_loss: 1.0125\n",
      "Epoch 5/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0692 - val_loss: 1.0122\n",
      "Epoch 6/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0692 - val_loss: 1.0112\n",
      "Epoch 7/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0692 - val_loss: 1.0116\n",
      "Epoch 8/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0693 - val_loss: 1.0121\n",
      "Epoch 9/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0694 - val_loss: 1.0136\n",
      "Epoch 10/10\n",
      "180849/180849 [==============================] - 0s - loss: 1.0694 - val_loss: 1.0123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11aad71d0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.fit([train_mean, train_std], train_set.targets, epochs=10, \n",
    "                batch_size=1024, \n",
    "                validation_data=[[test_mean, test_std], test_set.targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get a very similar CRPS compared to the 25 day rolling window. This suggests that the seasonality is not that important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = model_keras.predict([test_mean, test_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "results_df = create_results_df(test_set.date_strs, test_set.station_ids,\n",
    "                               preds[:, 0], preds[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mean</th>\n",
       "      <th>station_id</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4.507663</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.652217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.691526</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.386979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.661479</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.772558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4.462898</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.700408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2.021837</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.544789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      mean  station_id       std\n",
       "0  2016-01-01  4.507663        44.0  1.652217\n",
       "1  2016-01-01  1.691526        71.0  2.386979\n",
       "2  2016-01-01  0.661479        73.0  1.772558\n",
       "3  2016-01-01  4.462898        78.0  1.700408\n",
       "4  2016-01-01  2.021837        91.0  2.544789"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df.to_csv(results_dir + 'emos_network_train_2015_pred_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
